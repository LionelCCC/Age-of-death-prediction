{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deepsurv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U sentence-transformers > /dev/null 2>&1\n",
    "!pip install xgboost > /dev/null 2>&1\n",
    "!pip install scikit-learn==1.4.2 scikit-survival==0.23.1 > /dev/null 2>&1\n",
    "!pip install torchtuples > /dev/null 2>&1\n",
    "!pip install pycox > /dev/null 2>&1\n",
    "!pip install numpy==1.21.5  > /dev/null 2>&1\n",
    "!pip install interpret-core  > /dev/null 2>&1\n",
    "!pip install lightgbm > /dev/null 2>&1\n",
    "!pip install shap > /dev/null 2>&1\n",
    "!pip install lifelines pycox > /dev/null 2>&1\n",
    "!pip install pycountry > /dev/null 2>&1\n",
    "!pip install -U sentence-transformers xgboost scikit-learn==1.4.2 scikit-survival==0.23.1 torchtuples pycox numpy==1.21.5 interpret-core lightgbm shap lifelines pycox pycountry > /dev/null 2>&1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torchtuples as tt\n",
    "import kagglehub\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lifelines import CoxPHFitter\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from pycox.models.cox import CoxPH\n",
    "from pycox.evaluation import EvalSurv\n",
    "from pycox import models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Pandas Display Options to try to force full output ---\n",
    "pd.set_option('display.max_rows', None)  # Show all rows\n",
    "pd.set_option('display.max_columns', 50) # Adjust as needed\n",
    "pd.set_option('display.width', 1000)     # Adjust as needed\n",
    "pd.set_option('display.max_colwidth', None) # Show full column content\n",
    "pd.set_option('display.float_format', '{:.4f}'.format) # Optional: format floats\n",
    "\n",
    "feature_list = ['stress_score', 'avg_bmi', 'smoking_prev', 'global_life_exp'] # Define feature_list globally\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.7).\n",
      "Life Expectancy Sample:\n",
      "       Country  Year      Status  Life expectancy   Adult Mortality  infant deaths  Alcohol  percentage expenditure  Hepatitis B  Measles     BMI   under-five deaths    Polio  Total expenditure  Diphtheria    HIV/AIDS      GDP    Population   thinness  1-19 years   thinness 5-9 years  Income composition of resources  Schooling\n",
      "0  Afghanistan  2015  Developing           65.0000         263.0000             62   0.0100                 71.2796      65.0000      1154 19.1000                  83  6.0000             8.1600      65.0000     0.1000 584.2592 33736494.0000                17.2000              17.3000                           0.4790    10.1000\n",
      "1  Afghanistan  2014  Developing           59.9000         271.0000             64   0.0100                 73.5236      62.0000       492 18.6000                  86 58.0000             8.1800      62.0000     0.1000 612.6965   327582.0000                17.5000              17.5000                           0.4760    10.0000\n",
      "2  Afghanistan  2013  Developing           59.9000         268.0000             66   0.0100                 73.2192      64.0000       430 18.1000                  89 62.0000             8.1300      64.0000     0.1000 631.7450 31731688.0000                17.7000              17.7000                           0.4700     9.9000\n",
      "3  Afghanistan  2012  Developing           59.5000         272.0000             69   0.0100                 78.1842      67.0000      2787 17.6000                  93 67.0000             8.5200      67.0000     0.1000 669.9590  3696958.0000                17.9000              18.0000                           0.4630     9.8000\n",
      "4  Afghanistan  2011  Developing           59.2000         275.0000             71   0.0100                  7.0971      68.0000      3013 17.2000                  97 68.0000             7.8700      68.0000     0.1000  63.5372  2978599.0000                18.2000              18.2000                           0.4540     9.5000\n",
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.7).\n",
      "Heart Failure Sample:\n",
      "   Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  MaxHR ExerciseAngina  Oldpeak ST_Slope  HeartDisease\n",
      "0   40   M           ATA        140          289          0     Normal    172              N   0.0000       Up             0\n",
      "1   49   F           NAP        160          180          0     Normal    156              N   1.0000     Flat             1\n",
      "2   37   M           ATA        130          283          0         ST     98              N   0.0000       Up             0\n",
      "3   48   F           ASY        138          214          0     Normal    108              Y   1.5000     Flat             1\n",
      "4   54   M           NAP        150          195          0     Normal    122              N   0.0000       Up             0\n",
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.7).\n",
      "Age Dataset Sample:\n",
      "     Id                     Name                                Short description Gender                                             Country  Occupation  Birth year  Death year Manner of death  Age of death\n",
      "0   Q23        George Washington   1st president of the United States (1732–1799)   Male  United States of America; Kingdom of Great Britain  Politician        1732   1799.0000  natural causes       67.0000\n",
      "1   Q42            Douglas Adams                      English writer and humorist   Male                                      United Kingdom      Artist        1952   2001.0000  natural causes       49.0000\n",
      "2   Q91          Abraham Lincoln  16th president of the United States (1809-1865)   Male                            United States of America  Politician        1809   1865.0000        homicide       56.0000\n",
      "3  Q254  Wolfgang Amadeus Mozart        Austrian composer of the Classical period   Male     Archduchy of Austria; Archbishopric of Salzburg      Artist        1756   1791.0000             NaN       35.0000\n",
      "4  Q255     Ludwig van Beethoven           German classical and romantic composer   Male                  Holy Roman Empire; Austrian Empire      Artist        1770   1827.0000             NaN       57.0000\n",
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.7).\n",
      "World Important Events Sample:\n",
      "   Sl. No                      Name of Incident     Date    Month     Year Country Type of Event    Place Name                                                          Impact                      Affected Population Important Person/Group Responsible   Outcome\n",
      "0       1  Indus Valley Civilization Flourishes  Unknown  Unknown  2600 BC   India  Civilization  Indus Valley  Development of one of the world's earliest urban civilizations                        Local inhabitants                Indus Valley people  Positive\n",
      "1       2               Battle of the Ten Kings  Unknown  Unknown  1400 BC   India        Battle        Punjab      Rigvedic tribes consolidated their control over the region                          Rigvedic tribes                              Sudas  Positive\n",
      "2       6  Establishment of the Delhi Sultanate  Unknown  Unknown     1206   India     Political         Delhi                       Muslim rule established in parts of India  People of Delhi and surrounding regions      QutbUnknownudUnknowndin Aibak     Mixed\n",
      "3       7                     Battle of Panipat       21    April     1526   India        Battle       Panipat                        Foundation of the Mughal Empire in India                 Northern Indian kingdoms                              Babur     Mixed\n",
      "4       8          Establishment of British Raj        1      May     1858   India      Colonial   Whole India                     Start of direct British governance in India                      Indian subcontinent  British East India Company/Empire  Negative\n",
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.7).\n",
      "Historical Plane Crashes Sample:\n",
      "                 date     time                            location                operator flight_no          route                 ac_type registration cn_ln                       aboard                   fatalities ground                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           summary\n",
      "0  September 17, 1908    17:18                 Fort Myer, Virginia    Military - U.S. Army         ?  Demonstration        Wright Flyer III            ?     1   2   (passengers:1  crew:1)   1   (passengers:1  crew:0)      0  During a demonstration flight, a U.S. Army flyer flown by Orville Wright nose-dived into the ground from a height of approximately 75 feet, killing Lt. Thomas E. Selfridge, 26, who was a passenger. This was the first recorded airplane fatality in history.  One of two propellers separated in flight, tearing loose the wires bracing the rudder and causing the loss of control of the aircraft.  Orville Wright suffered broken ribs, pelvis and a leg.  Selfridge suffered a crushed skull and died a short time later.\n",
      "1  September 07, 1909        ?             Juvisy-sur-Orge, France                       ?         ?       Air show          Wright Byplane          SC1     ?   1   (passengers:0  crew:1)   1   (passengers:0  crew:0)      0                                                                                                                                                                                                                                                                                                                                                                                                  Eugene Lefebvre was the first pilot to ever be killed in an air accident, after his controls jambed while flying in an air show.\n",
      "2       July 12, 1912    06:30           Atlantic City, New Jersey    Military - U.S. Navy         ?    Test flight               Dirigible            ?     ?   5   (passengers:0  crew:5)   5   (passengers:0  crew:5)      0                                                                                                                                                                                                                                                                                                                                                                                                                               First U.S. dirigible Akron exploded just offshore at an altitude of 1,000 ft. during a test flight.\n",
      "3     August 06, 1913        ?  Victoria, British Columbia, Canada                 Private         ?              ?        Curtiss seaplane            ?     ?   1   (passengers:0  crew:1)   1   (passengers:0  crew:1)      0                                                                                                                                                                                                                                                                                                                                                                                                    The first fatal airplane accident in Canada occurred when American barnstormer, John M. Bryant, California aviator was killed.\n",
      "4  September 09, 1913  c 18:30                  Over the North Sea  Military - German Navy         ?              ?  Zeppelin L-1 (airship)            ?     ?  20   (passengers:?  crew:?)  14   (passengers:?  crew:?)      0                                                                                                                                                                                                                                                                                                              The airship flew into a thunderstorm and encountered a severe downdraft crashing 20 miles north of Helgoland Island into the sea. The ship broke in two and the control car immediately sank drowning its occupants.\n",
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.7).\n",
      "Global Life Expectancy Historical Dataset Sample:\n",
      "           Country Name Country Code    1960    1961    1962    1963    1964    1965    1966    1967    1968    1969    1970    1971    1972    1973    1974    1975    1976    1977    1978    1979    1980    1981    1982  ...    1996    1997    1998    1999    2000    2001    2002    2003    2004    2005    2006    2007    2008    2009    2010    2011    2012    2013    2014    2015    2016    2017    2018    2019    2020\n",
      "0                 Aruba          ABW 65.6620 66.0740 66.4440 66.7870 67.1130 67.4350 67.7620 68.0950 68.4360 68.7840 69.1400 69.4980 69.8510 70.1910 70.5190 70.8330 71.1400 71.4410 71.7360 72.0230 72.2930 72.5380 72.7510  ... 73.6460 73.6710 73.7000 73.7380 73.7870 73.8530 73.9370 74.0380 74.1560 74.2870 74.4290 74.5760 74.7250 74.8720 75.0170 75.1580 75.2990 75.4410 75.5830 75.7250 75.8680 76.0100 76.1520 76.2930 76.4340\n",
      "1           Afghanistan          AFG 32.4460 32.9620 33.4710 33.9710 34.4630 34.9480 35.4300 35.9140 36.4030 36.9000 37.4090 37.9300 38.4610 39.0030 39.5580 40.1280 40.7150 41.3200 41.9440 42.5850 43.2440 43.9230 44.6170  ... 53.9240 54.4240 54.9060 55.3760 55.8410 56.3080 56.7840 57.2710 57.7720 58.2900 58.8260 59.3750 59.9300 60.4840 61.0280 61.5530 62.0540 62.5250 62.9660 63.3770 63.7630 64.1300 64.4860 64.8330 65.1730\n",
      "2                Angola          AGO 37.5240 37.8110 38.1130 38.4300 38.7600 39.1020 39.4540 39.8130 40.1780 40.5460 40.9140 41.2820 41.6500 42.0160 42.3740 42.7210 43.0530 43.3670 43.6600 43.9310 44.1780 44.4040 44.6110  ... 45.3500 45.5190 45.7630 46.0930 46.5220 47.0590 47.7020 48.4400 49.2630 50.1650 51.1430 52.1770 53.2430 54.3110 55.3500 56.3300 57.2360 58.0540 58.7760 59.3980 59.9250 60.3790 60.7820 61.1470 61.4870\n",
      "3               Albania          ALB 62.2830 63.3010 64.1900 64.9140 65.4630 65.8500 66.1100 66.3040 66.4870 66.6890 66.9350 67.2370 67.5820 67.9530 68.3430 68.7360 69.1100 69.4480 69.7420 69.9910 70.2080 70.4160 70.6350  ... 72.4950 72.8380 73.2080 73.5870 73.9550 74.2880 74.5790 74.8280 75.0390 75.2280 75.4230 75.6460 75.9120 76.2210 76.5620 76.9140 77.2520 77.5540 77.8130 78.0250 78.1940 78.3330 78.4580 78.5730 78.6860\n",
      "4  United Arab Emirates          ARE 51.5370 52.5600 53.5730 54.5720 55.5550 56.5230 57.4820 58.4320 59.3750 60.3040 61.2150 62.0990 62.9490 63.7590 64.5250 65.2440 65.9160 66.5450 67.1370 67.6920 68.2130 68.7010 69.1580  ... 73.4280 73.6570 73.8830 74.1060 74.3270 74.5440 74.7580 74.9680 75.1740 75.3760 75.5730 75.7670 75.9570 76.1450 76.3320 76.5210 76.7110 76.9030 77.0950 77.2850 77.4700 77.6470 77.8140 77.9720 78.1200\n",
      "\n",
      "[5 rows x 63 columns]\n",
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.7).\n",
      "Death Rates United States Dataset Sample:\n",
      "                 INDICATOR                                                  UNIT  UNIT_NUM STUB_NAME  STUB_NAME_NUM   STUB_LABEL  STUB_LABEL_NUM  YEAR  YEAR_NUM       AGE  AGE_NUM  ESTIMATE\n",
      "0  Death rates for suicide  Deaths per 100,000 resident population, age-adjusted         1     Total              0  All persons          0.0000  1950         1  All ages   0.0000   13.2000\n",
      "1  Death rates for suicide  Deaths per 100,000 resident population, age-adjusted         1     Total              0  All persons          0.0000  1960         2  All ages   0.0000   12.5000\n",
      "2  Death rates for suicide  Deaths per 100,000 resident population, age-adjusted         1     Total              0  All persons          0.0000  1970         3  All ages   0.0000   13.1000\n",
      "3  Death rates for suicide  Deaths per 100,000 resident population, age-adjusted         1     Total              0  All persons          0.0000  1980         4  All ages   0.0000   12.2000\n",
      "4  Death rates for suicide  Deaths per 100,000 resident population, age-adjusted         1     Total              0  All persons          0.0000  1981         5  All ages   0.0000   12.3000\n"
     ]
    }
   ],
   "source": [
    "# Life Expectancy dataset\n",
    "life_exp_path = kagglehub.dataset_download(\"kumarajarshi/life-expectancy-who\")\n",
    "life_exp_file = os.path.join(life_exp_path, \"Life Expectancy Data.csv\")\n",
    "life_exp_df = pd.read_csv(life_exp_file)\n",
    "print(\"Life Expectancy Sample:\")\n",
    "print(life_exp_df.head())\n",
    "\n",
    "# Heart Failure dataset (not used in LightGBM, but kept for context)\n",
    "heart_path = kagglehub.dataset_download(\"fedesoriano/heart-failure-prediction\")\n",
    "heart_file = os.path.join(heart_path, \"heart.csv\")\n",
    "heart_df = pd.read_csv(heart_file)\n",
    "print(\"Heart Failure Sample:\")\n",
    "print(heart_df.head())\n",
    "\n",
    "# Age Dataset\n",
    "age_path = kagglehub.dataset_download(\"imoore/age-dataset\")\n",
    "age_file = os.path.join(age_path, \"AgeDataset-V1.csv\")\n",
    "age_df = pd.read_csv(age_file)\n",
    "print(\"Age Dataset Sample:\")\n",
    "print(age_df.head())\n",
    "\n",
    "# World important events Dataset\n",
    "events_path = kagglehub.dataset_download(\"saketk511/world-important-events-ancient-to-modern\")\n",
    "events_file = os.path.join(events_path, \"World Important Dates.csv\")\n",
    "events_df = pd.read_csv(events_file)\n",
    "print(\"World Important Events Sample:\")\n",
    "print(events_df.head())\n",
    "\n",
    "# Plane Crash Dataset\n",
    "plane_crash_path = kagglehub.dataset_download(\"nguyenhoc/plane-crash\")\n",
    "plane_crash_file = os.path.join(plane_crash_path, \"planecrashinfo_20181121001952.csv\")  \n",
    "planes_df = pd.read_csv(plane_crash_file)\n",
    "print(\"Historical Plane Crashes Sample:\")\n",
    "print(planes_df.head())\n",
    "\n",
    "# Gloabl Life Expectancy dataset\n",
    "global_le_path = kagglehub.dataset_download(\"hasibalmuzdadid/global-life-expectancy-historical-dataset\")\n",
    "global_le_file = os.path.join(global_le_path, \"global life expectancy dataset.csv\")\n",
    "global_le_df = pd.read_csv(global_le_file)\n",
    "print(\"Global Life Expectancy Historical Dataset Sample:\")\n",
    "print(global_le_df.head())\n",
    "\n",
    "# US death rate Dataset\n",
    "death_rates_path = kagglehub.dataset_download(\"melissamonfared/death-rates-united-states\")\n",
    "death_rates_file = os.path.join(death_rates_path, \"Death_rates.csv\")\n",
    "death_rates_df = pd.read_csv(death_rates_file)\n",
    "print(\"Death Rates United States Dataset Sample:\")\n",
    "print(death_rates_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhanced_feature_engineering(df, life_exp_df, global_le_df, death_rates_df):\n",
    "    \"\"\"\n",
    "    Enhanced feature engineering with comprehensive NaN debugging prints.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Enhanced Feature Engineering ---\")\n",
    "\n",
    "    # -------- Validate Input Columns --------\n",
    "    required_columns = {'Country', 'Gender', 'Occupation', 'Birth year',\n",
    "                        'Death year', 'Age of death'}\n",
    "    missing = required_columns - set(df.columns)\n",
    "    if missing:\n",
    "        raise KeyError(f\"Missing required columns: {missing}\")\n",
    "    print(\"✅ Input columns validated.\")\n",
    "\n",
    "    # -------- Set Observation Year --------\n",
    "    current_year = 2019\n",
    "\n",
    "    # -------- Handle Initial NaNs in 'Country' --------\n",
    "    print(\"\\n🔍 Checking and handling initial NaNs in 'Country'...\")\n",
    "    initial_nan_count_country = df['Country'].isnull().sum()\n",
    "    print(f\"   Initial NaNs in Country: {initial_nan_count_country}\")\n",
    "\n",
    "    # Impute NaNs in 'Country' with 'Unknown Country' *before* cleaning\n",
    "    df['Country'] = df['Country'].fillna('Unknown Country')\n",
    "    print(\"   ✅ NaNs in 'Country' imputed with 'Unknown Country'.\")\n",
    "    nan_count_after_imputation = df['Country'].isnull().sum()\n",
    "    print(f\"   NaNs in Country after imputation: {nan_count_after_imputation} (Should be 0)\")\n",
    "    \n",
    "    # FIXED: Create proper event indicator (1 = death observed, 0 = censored)\n",
    "    df['event'] = (df['Death year'] <= current_year).astype(int)  # CORRECTED\n",
    "\n",
    "    # Calculate time-to-event\n",
    "    df['T'] = np.where(\n",
    "        df['event'] == 0,  # If censored (no event)\n",
    "        current_year - df['Birth year'],  # Time until censoring\n",
    "        df['Age of death']  # If event observed, use actual age\n",
    "    )\n",
    "\n",
    "    # -------- Basic Cleaning --------\n",
    "    print(\"\\n🧹 Basic Cleaning...\")\n",
    "    df['Country'] = df['Country'].str.split(';').str[0].str.strip()\n",
    "    df['Gender'] = np.where(df['Gender'] == 'Male', 1,\n",
    "                          np.where(df['Gender'] == 'Female', 0, 0.5))\n",
    "    print(\"   ✅ Country and Gender cleaned.\")\n",
    "    print(f\"   Sample age_df countries after cleaning: {df['Country'].unique()[:20]}\")\n",
    "    print(f\"   Sample global_le_df countries: {global_le_df['Country Name'].unique()[:20]}\")\n",
    "    print(\"\\n🔍 Sample global_le_agg countries BEFORE merge:\")  # Inspect global_le_agg countries before merge\n",
    "    global_le_melted = global_le_df.melt(\n",
    "        id_vars=['Country Name', 'Country Code'],\n",
    "        value_vars=[str(y) for y in range(1960, current_year+1)],\n",
    "        var_name='Year',\n",
    "        value_name='Life_Exp_Value'\n",
    "    )\n",
    "\n",
    "    global_le_agg = (\n",
    "        global_le_melted\n",
    "        .sort_values(['Country Name', 'Year'], ascending=[True, False])\n",
    "        .groupby('Country Name')\n",
    "        ['Life_Exp_Value']\n",
    "        .first()\n",
    "        .reset_index()\n",
    "        .rename(columns={'Country Name': 'Country'})\n",
    "    )\n",
    "    print(f\"   Unique countries in global_le_agg: {global_le_agg['Country'].unique()[:20]}\") # Sample of unique countries in global_le_agg\n",
    "\n",
    "\n",
    "    # Check for NaNs after basic cleaning (should be minimal now)\n",
    "    print(\"🔍 Checking for NaNs after basic cleaning:\")\n",
    "    print(f\"   NaNs in Country: {df['Country'].isnull().sum()}\") # Expecting 0 or very few\n",
    "    print(f\"   NaNs in Gender: {df['Gender'].isnull().sum()}\")\n",
    "\n",
    "\n",
    "    # -------- Clinical Features (Rest remains the same) --------\n",
    "    print(\"\\n🧬 Engineering Clinical Features...\")\n",
    "    stress_map = {'Politician': 9, 'Military personnel': 8, 'Journalist': 7,\n",
    "                  'Businessperson': 6, 'Artist': 5, 'Teacher': 4,\n",
    "                  'Researcher': 3, 'Other': 5, 'Unknown': 5}\n",
    "    df['stress_score'] = df['Occupation'].map(stress_map).fillna(5).astype('float32') / 9.0\n",
    "    print(\"   ✅ Stress score engineered.\")\n",
    "\n",
    "    life_exp_df[' BMI '] = pd.to_numeric(life_exp_df[' BMI '], errors='coerce')\n",
    "    country_bmi = life_exp_df.groupby('Country')[' BMI '].median().to_dict()\n",
    "    df['avg_bmi'] = df['Country'].map(country_bmi).fillna(25).astype('float32')\n",
    "    print(\"   ✅ Avg BMI engineered.\")\n",
    "\n",
    "    df['smoking_prev'] = (1 / (1 + np.exp((df['Birth year'] - 1950) / 10))).astype('float32')\n",
    "    df['smoking_prev'] = np.clip(df['smoking_prev'], 0.1, 0.6)\n",
    "    print(\"   ✅ Smoking prevalence engineered.\")\n",
    "\n",
    "    # Check for NaNs after clinical feature engineering\n",
    "    print(\"🔍 Checking for NaNs after clinical features:\")\n",
    "    print(f\"   NaNs in stress_score: {df['stress_score'].isnull().sum()}\")\n",
    "    print(f\"   NaNs in avg_bmi: {df['avg_bmi'].isnull().sum()}\")\n",
    "    print(f\"   NaNs in smoking_prev: {df['smoking_prev'].isnull().sum()}\")\n",
    "\n",
    "\n",
    "    # -------- Country-Level Features --------\n",
    "    print(\"\\n🌍 Engineering Country-Level Features...\")\n",
    "    print(\"\\nSample global_le_agg before merge:\") # Inspect global_le_agg\n",
    "    global_le_melted = global_le_df.melt(\n",
    "        id_vars=['Country Name', 'Country Code'],\n",
    "        value_vars=[str(y) for y in range(1960, current_year+1)],\n",
    "        var_name='Year',\n",
    "        value_name='Life_Exp_Value'\n",
    "    )\n",
    "\n",
    "    global_le_agg = (\n",
    "        global_le_melted\n",
    "        .sort_values(['Country Name', 'Year'], ascending=[True, False])\n",
    "        .groupby('Country Name')\n",
    "        ['Life_Exp_Value']\n",
    "        .first()\n",
    "        .reset_index()\n",
    "        .rename(columns={'Country Name': 'Country'})\n",
    "    )\n",
    "    print(global_le_agg.head()) # Print head of global_le_agg\n",
    "    print(f\"   NaNs in global_le_agg['Country']: {global_le_agg['Country'].isnull().sum()}\") # Check NaNs in global_le_agg['Country']\n",
    "    print(f\"   NaNs in global_le_agg['Life_Exp_Value']: {global_le_agg['Life_Exp_Value'].isnull().sum()}\") # Check NaNs in global_le_agg['Life_Exp_Value']\n",
    "\n",
    "\n",
    "    df = df.merge(global_le_agg, on='Country', how='left')\n",
    "    df['global_life_exp'] = df['Life_Exp_Value'].fillna(df['Life_Exp_Value'].median()) #median imputation to avoid NaN\n",
    "    print(\"   ✅ Global Life Expectancy engineered.\")\n",
    "\n",
    "    # Check for NaNs after country-level feature engineering\n",
    "    print(\"🔍 Checking for NaNs after country-level features:\")\n",
    "    print(f\"   NaNs in global_life_exp: {df['global_life_exp'].isnull().sum()}\")\n",
    "\n",
    "\n",
    "    # -------- Survival Data Setup --------\n",
    "    print(\"\\n⏳ Survival Data Setup...\")\n",
    "    current_year = 2019 # Re-declare to ensure it's available in this scope if needed\n",
    "\n",
    "    df['censored'] = (df['Death year'] > current_year).astype(int)\n",
    "\n",
    "    # Revised 'T' calculation to handle missing 'Age of death' robustly\n",
    "    df['T'] = np.where(\n",
    "        df['censored'] == 1, # If censored (still alive as of current_year)\n",
    "        current_year - df['Birth year'], # T = time until observation (censoring time)\n",
    "        df['Age of death'] # Else (event observed), T = Age of death\n",
    "    )\n",
    "\n",
    "    # Handle potential NaNs in 'T' *after* the calculation, specifically for cases where Age of death is missing for non-censored cases.\n",
    "    # In such cases, we might default to a large value or impute based on other information if available, or drop the row if no imputation is reasonable.\n",
    "    # For now, let's impute with a plausible value (e.g., median age of death for non-censored individuals) or simply drop the row for simplicity.\n",
    "    median_age_death_non_censored = df[df['censored'] == 0]['Age of death'].median()\n",
    "    df['T'] = df['T'].fillna(median_age_death_non_censored).clip(0, 120) # Impute and clip\n",
    "\n",
    "    print(\"   ✅ Survival time (T) and censoring engineered.\")\n",
    "\n",
    "    # Final check for NaNs in critical columns\n",
    "    print(\"\\n🔍 Final NaN check before returning:\")\n",
    "    print(f\"   NaNs in censored: {df['censored'].isnull().sum()}\")\n",
    "    print(f\"   NaNs in T: {df['T'].isnull().sum()}\")\n",
    "    print(\"\\nSample processed_batch after feature engineering:\") # Inspect processed_batch\n",
    "    print(df.head())\n",
    "    print(f\"   NaNs in processed_batch after FE: {df[feature_list + ['T', 'censored']].isnull().sum().sum()}\") # Total NaNs in features and targets after FE\n",
    "\n",
    "\n",
    "    print(\"✅ Enhanced feature engineering completed.\\n\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepSurv(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(DeepSurv, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_deepsurv_model(df):\n",
    "    \"\"\"\n",
    "    Train and evaluate DeepSurv model with NaN debugging, focusing on 'T'.\n",
    "    Simplified logging - printing model.log object directly in epoch loop.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Train DeepSurv Model ---\")\n",
    "\n",
    "    # feature_list = ['stress_score', 'avg_bmi', 'smoking_prev', 'global_life_exp'] # Defined globally\n",
    "\n",
    "    # Ensure required features exist\n",
    "    missing_features = set(feature_list) - set(df.columns)\n",
    "    if missing_features:\n",
    "        raise KeyError(f\"Missing required features: {missing_features}. Available: {df.columns.tolist()}\")\n",
    "    print(\"✅ Required features validated.\")\n",
    "\n",
    "    # Extract Data\n",
    "    X = df[feature_list].values.astype('float32')\n",
    "    durations = df['T'].values.astype('float32')\n",
    "    events = df['event'].values.astype('int')  # WAS df['censored']\n",
    "\n",
    "    # Debugging: Check Data Before Training - NaN Check!\n",
    "    print(\"\\n📊 Checking Data Before Training DeepSurv (Detailed NaN Check):\")\n",
    "    print(f\"Feature Shape: {X.shape}, Durations Shape: {durations.shape}, Events Shape: {events.shape}\")\n",
    "    print(\"NaN counts per column BEFORE training:\")\n",
    "    nan_counts = df[feature_list + ['T', 'censored']].isnull().sum() # NaN count for each feature and target\n",
    "    print(nan_counts) # Print NaN counts per column\n",
    "    print(f\"Total NaNs in Features and Targets BEFORE training: {nan_counts.sum()}\") # Total NaNs in features and targets\n",
    "    print(f\"Total NaNs in Features (X): {np.isnan(X).sum()}\")\n",
    "    print(f\"NaNs in Durations: {np.isnan(durations).sum()}\")\n",
    "    print(f\"NaNs in Events: {np.isnan(events).sum()}\")\n",
    "    print(f\"Sample Features:\\n{X[:5]}\")\n",
    "    print(f\"Sample Durations: {durations[:5]}\")\n",
    "    print(f\"Sample Events: {events[:5]}\")\n",
    "    print(f\"Unique event values (should be 0 or 1): {np.unique(events)}\")\n",
    "\n",
    "    # --- DEBUGGING: FIND ROW WITH NaN in 'T' ---\n",
    "    nan_T_mask = df['T'].isnull()\n",
    "    if nan_T_mask.any():\n",
    "        print(\"\\n🚨🚨🚨 NaN DETECTED in 'T' column! 🚨🚨🚨\")\n",
    "        nan_T_row_index = df[nan_T_mask].index[0] # Get index of first NaN row\n",
    "        print(f\"Index of row with NaN in 'T': {nan_T_row_index}\")\n",
    "        print(\"Problematic row data:\")\n",
    "        print(df.loc[[nan_T_row_index]]) # Print the entire row\n",
    "    else:\n",
    "        print(\"\\n✅ No NaNs detected in 'T' column (so far in NaN check).\")\n",
    "\n",
    "\n",
    "    if np.isnan(X).any() or np.isnan(durations).any() or np.isnan(events).any():\n",
    "        raise ValueError(\"NaNs detected in input data, cannot proceed with training.\")\n",
    "    print(\"✅ No NaNs in input data for training.\")\n",
    "\n",
    "\n",
    "    # Train-Test Split (Rest of the function remains unchanged)\n",
    "    X_train, X_val, durations_train, durations_val, events_train, events_val = train_test_split(\n",
    "        X, durations, events, test_size=0.2, random_state=42\n",
    "    )\n",
    "    print(\"   ✅ Data split into training and validation sets.\")\n",
    "\n",
    "\n",
    "    # Normalize Features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    print(\"   ✅ Features normalized using StandardScaler.\")\n",
    "    print(f\"NaNs in Scaled X_train: {np.isnan(X_train).sum()}\")\n",
    "    print(f\"NaNs in Scaled X_val: {np.isnan(X_val).sum()}\")\n",
    "    if np.isnan(X_train).any() or np.isnan(X_val).any():\n",
    "        raise ValueError(\"NaNs detected in scaled data, check feature engineering and scaling.\")\n",
    "    print(\"✅ No NaNs in scaled data.\")\n",
    "\n",
    "    # --- Additional Data Sanity Checks RIGHT BEFORE model.fit() ---\n",
    "    print(\"\\n📊 Data Sanity Check RIGHT BEFORE model.fit():\")\n",
    "    print(f\"X_train NaNs: {np.isnan(X_train).sum()}, Durations NaNs: {np.isnan(durations_train).sum()}, Events NaNs: {np.isnan(events_train).sum()}\")\n",
    "    print(f\"X_val NaNs: {np.isnan(X_val).sum()}, Durations Val NaNs: {np.isnan(durations_val).sum()}, Events Val NaNs: {np.isnan(events_val).sum()}\")\n",
    "\n",
    "    print(f\"X_train dtype: {X_train.dtype}, Durations dtype: {durations_train.dtype}, Events dtype: {events_train.dtype}\")\n",
    "\n",
    "    print(f\"X_train min/max: {X_train.min():.4f} / {X_train.max():.4f}\")\n",
    "    print(f\"Durations min/max: {durations_train.min():.4f} / {durations_train.max():.4f}\")\n",
    "    print(f\"Events unique values: {np.unique(events_train)}\")\n",
    "\n",
    "\n",
    "    # DeepSurv Model Setup\n",
    "    in_features = X_train.shape[1]\n",
    "    num_nodes = [64, 64]\n",
    "    out_features = 1\n",
    "    batch_norm = True\n",
    "    dropout = 0.1\n",
    "    net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm, dropout)\n",
    "    model = models.CoxPH(net, tt.optim.Adam(lr=0.0005)) # Reduced LR\n",
    "\n",
    "    print(\"\\n🚀 Training DeepSurv Model...\")\n",
    "    print(f\"✅ DeepSurv Model Initialized with {in_features} input features.\")\n",
    "    print(f\"Hidden Layers: {num_nodes}, Dropout: {dropout}, Learning Rate: 0.0005\")\n",
    "\n",
    "    epochs = 100 # Reduced for testing, increase later\n",
    "    batch_size = 256\n",
    "    verbose = True # Keep verbose for detailed output\n",
    "\n",
    "    print(f\"Training parameters: Epochs={epochs}, Batch Size={batch_size}, Verbose={verbose}\")\n",
    "\n",
    "    # ✅ SIMPLIFIED EPOCH LOOP - Inspecting model.log Directly\n",
    "    for epoch in range(epochs): # Manual epoch loop\n",
    "        log = model.fit(\n",
    "            X_train, (durations_train, events_train),\n",
    "            batch_size=batch_size, epochs=epochs, verbose=True,\n",
    "            val_data=(X_val, (durations_val, events_val)),\n",
    "            callbacks=[tt.callbacks.EarlyStopping()],\n",
    "            num_workers=0\n",
    "        )\n",
    "        print(\"\\n📈 Training Logs:\")\n",
    "        print(log.to_pandas().tail())\n",
    "        # --- NEW: Correctly print loss from model.log.values ---\n",
    "        if hasattr(model, 'log') and hasattr(model.log, 'values'): # Check if log and values exist\n",
    "            log_values = model.log.values\n",
    "            train_loss = log_values.get('loss') # Get training loss\n",
    "            val_loss = log_values.get('val_loss') # Get validation loss (if available)\n",
    "\n",
    "            print(f\"\\n--- Epoch {epoch+1} ---\")\n",
    "            print(f\"  Epoch {epoch+1}, Training Loss: {train_loss:.4f}\") # Print training loss\n",
    "            if val_loss is not None:\n",
    "                print(f\"  Epoch {epoch+1}, Validation Loss: {val_loss:.4f}\") # Print validation loss if available\n",
    "        else:\n",
    "            print(f\"\\n--- Epoch {epoch+1} ---\")\n",
    "            print(f\"  Epoch {epoch+1}, model.log or model.log.values is not available.\")\n",
    "\n",
    "\n",
    "    print(\"✅ DeepSurv model training completed.\")\n",
    "\n",
    "    # --- NEW: Check model.log and model parameters AFTER training ---\n",
    "    print(\"\\n📊 Checking model.log AFTER training:\")\n",
    "    if hasattr(model, 'log') and model.log:\n",
    "        print(f\"model.log type AFTER training: {type(model.log)}\")\n",
    "        print(f\"Sample model.log AFTER training: {model.log[:5]}\") # Print first 5 entries\n",
    "    else:\n",
    "        print(\"model.log is empty or not available.\")\n",
    "\n",
    "    print(\"\\n🔬 Inspecting Model Parameters (Weights/Biases - First Layer):\")\n",
    "    for name, param in model.net.named_parameters(): # net is the MLPVanilla network\n",
    "        if \"0\" in name and (\"weight\" in name or \"bias\" in name): # Inspect weights/biases of first layer\n",
    "            print(f\"Layer Parameter '{name}':\")\n",
    "            print(f\"  Shape: {param.shape}\")\n",
    "            print(f\"  Sample Values:\\n{param[:2,:2].detach().numpy()}\") # Print snippet of weights/biases\n",
    "            print(f\"  NaNs: {torch.isnan(param).sum()}\")\n",
    "            print(f\"  Inf: {torch.isinf(param).sum()}\")\n",
    "            print(f\"  Min/Max/Mean: {param.min().item():.4f} / {param.max().item():.4f} / {param.mean().item():.4f}\")\n",
    "\n",
    "\n",
    "    # Compute Baseline Hazards\n",
    "    print(\"\\n📊 Computing Baseline Hazards...\")\n",
    "    model.compute_baseline_hazards()\n",
    "    print(\"✅ Baseline hazards computed.\")\n",
    "\n",
    "    # Get Predictions\n",
    "    print(\"\\n🔮 Making Survival Predictions...\")\n",
    "    surv = model.predict_surv_df(X_val)\n",
    "\n",
    "    # Check for NaNs in Survival Predictions AGAIN after training\n",
    "    if np.isnan(surv.values).any():\n",
    "        print(\"\\n❌ WARNING: Survival Predictions STILL Contain NaN Values AFTER TRAINING!\")\n",
    "        nan_count_in_surv = np.isnan(surv.values).sum()\n",
    "        print(f\"   Number of NaNs in Survival Predictions: {nan_count_in_surv}\")\n",
    "    else:\n",
    "        print(\"\\n✅ No NaN values in survival predictions.\")\n",
    "\n",
    "    # Evaluate Model\n",
    "    print(\"\\n📈 Evaluating Model Performance...\")\n",
    "    ev = EvalSurv(surv, durations_val, events_val, censor_surv='km')\n",
    "    c_index = ev.concordance_td('antolini')\n",
    "    print(f\"\\n📊 DeepSurv Concordance Index: {c_index:.4f}\")\n",
    "\n",
    "    print(\"✅ DeepSurv model training and evaluation completed.\\n\")\n",
    "    return model, X_val, durations_val, events_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_deepsurv_model(model, X_val, durations_val, events_val):\n",
    "    \"\"\"\n",
    "    Evaluate DeepSurv Model Performance using Concordance Index\n",
    "    \"\"\"\n",
    "    surv = model.predict_surv_df(X_val)\n",
    "    surv.index = pd.to_numeric(surv.index, errors='coerce')\n",
    "\n",
    "    if 0 not in surv.index:\n",
    "        new_row = pd.DataFrame(np.ones((1, surv.shape[1])), index=[0], columns=surv.columns)\n",
    "        surv = pd.concat([new_row, surv])\n",
    "        surv = surv.sort_index()\n",
    "\n",
    "    ev = EvalSurv(surv, durations_val, events_val, censor_surv='km')\n",
    "    c_index = ev.concordance_td('antolini')\n",
    "\n",
    "    print(f\"\\n📊 DeepSurv Concordance Index: {c_index:.4f}\")\n",
    "    return c_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Enhanced Feature Engineering ---\n",
      "✅ Input columns validated.\n",
      "\n",
      "🔍 Checking and handling initial NaNs in 'Country'...\n",
      "   Initial NaNs in Country: 335509\n",
      "   ✅ NaNs in 'Country' imputed with 'Unknown Country'.\n",
      "   NaNs in Country after imputation: 0 (Should be 0)\n",
      "\n",
      "🧹 Basic Cleaning...\n",
      "   ✅ Country and Gender cleaned.\n",
      "   Sample age_df countries after cleaning: ['United States of America' 'United Kingdom' 'Archduchy of Austria'\n",
      " 'Holy Roman Empire' 'Kingdom of France' 'France' 'Spain'\n",
      " 'Grand Duchy of Tuscany' 'Chile' 'Nazi Germany' 'Kingdom of Castile'\n",
      " 'Kingdom of the Netherlands' 'Byelorussian Soviet Socialist Republic'\n",
      " 'Czech Republic' 'Jamaica' 'German Empire' 'Denmark' 'Soviet Union'\n",
      " 'French Third Republic' 'Unknown Country']\n",
      "   Sample global_le_df countries: ['Aruba' 'Afghanistan' 'Angola' 'Albania' 'United Arab Emirates'\n",
      " 'Argentina' 'Armenia' 'Antigua and Barbuda' 'Australia' 'Austria'\n",
      " 'Azerbaijan' 'Burundi' 'Belgium' 'Benin' 'Burkina Faso' 'Bangladesh'\n",
      " 'Bulgaria' 'Bahrain' 'Bahamas, The' 'Bosnia and Herzegovina']\n",
      "\n",
      "🔍 Sample global_le_agg countries BEFORE merge:\n",
      "   Unique countries in global_le_agg: ['Afghanistan' 'Albania' 'Algeria' 'Angola' 'Antigua and Barbuda'\n",
      " 'Argentina' 'Armenia' 'Aruba' 'Australia' 'Austria' 'Azerbaijan'\n",
      " 'Bahamas, The' 'Bahrain' 'Bangladesh' 'Barbados' 'Belarus' 'Belgium'\n",
      " 'Belize' 'Benin' 'Bermuda']\n",
      "🔍 Checking for NaNs after basic cleaning:\n",
      "   NaNs in Country: 0\n",
      "   NaNs in Gender: 0\n",
      "\n",
      "🧬 Engineering Clinical Features...\n",
      "   ✅ Stress score engineered.\n",
      "   ✅ Avg BMI engineered.\n",
      "   ✅ Smoking prevalence engineered.\n",
      "🔍 Checking for NaNs after clinical features:\n",
      "   NaNs in stress_score: 0\n",
      "   NaNs in avg_bmi: 0\n",
      "   NaNs in smoking_prev: 0\n",
      "\n",
      "🌍 Engineering Country-Level Features...\n",
      "\n",
      "Sample global_le_agg before merge:\n",
      "               Country  Life_Exp_Value\n",
      "0          Afghanistan         64.8330\n",
      "1              Albania         78.5730\n",
      "2              Algeria         76.8800\n",
      "3               Angola         61.1470\n",
      "4  Antigua and Barbuda         77.0160\n",
      "   NaNs in global_le_agg['Country']: 0\n",
      "   NaNs in global_le_agg['Life_Exp_Value']: 0\n",
      "   ✅ Global Life Expectancy engineered.\n",
      "🔍 Checking for NaNs after country-level features:\n",
      "   NaNs in global_life_exp: 0\n",
      "\n",
      "⏳ Survival Data Setup...\n",
      "   ✅ Survival time (T) and censoring engineered.\n",
      "\n",
      "🔍 Final NaN check before returning:\n",
      "   NaNs in censored: 0\n",
      "   NaNs in T: 0\n",
      "\n",
      "Sample processed_batch after feature engineering:\n",
      "     Id                     Name                                Short description  Gender                   Country  Occupation  Birth year  Death year Manner of death  Age of death  event       T  stress_score  avg_bmi  smoking_prev  Life_Exp_Value  global_life_exp  censored\n",
      "0   Q23        George Washington   1st president of the United States (1732–1799)  1.0000  United States of America  Politician        1732   1799.0000  natural causes       67.0000      1 67.0000        1.0000  65.4000        0.6000             NaN          81.8951         0\n",
      "1   Q42            Douglas Adams                      English writer and humorist  1.0000            United Kingdom      Artist        1952   2001.0000  natural causes       49.0000      1 49.0000        0.5556  25.0000        0.4502         81.2049          81.2049         0\n",
      "2   Q91          Abraham Lincoln  16th president of the United States (1809-1865)  1.0000  United States of America  Politician        1809   1865.0000        homicide       56.0000      1 56.0000        1.0000  65.4000        0.6000             NaN          81.8951         0\n",
      "3  Q254  Wolfgang Amadeus Mozart        Austrian composer of the Classical period  1.0000      Archduchy of Austria      Artist        1756   1791.0000             NaN       35.0000      1 35.0000        0.5556  25.0000        0.6000             NaN          81.8951         0\n",
      "4  Q255     Ludwig van Beethoven           German classical and romantic composer  1.0000         Holy Roman Empire      Artist        1770   1827.0000             NaN       57.0000      1 57.0000        0.5556  25.0000        0.6000             NaN          81.8951         0\n",
      "   NaNs in processed_batch after FE: 0\n",
      "✅ Enhanced feature engineering completed.\n",
      "\n",
      "   Sample age_df countries: ['United States of America' 'United Kingdom' 'Archduchy of Austria'\n",
      " 'Holy Roman Empire' 'Kingdom of France' 'France' 'Spain'\n",
      " 'Grand Duchy of Tuscany' 'Chile' 'Nazi Germany' 'Kingdom of Castile'\n",
      " 'Kingdom of the Netherlands' 'Byelorussian Soviet Socialist Republic'\n",
      " 'Czech Republic' 'Jamaica' 'German Empire' 'Denmark' 'Soviet Union'\n",
      " 'French Third Republic' 'Unknown Country']\n",
      "\n",
      "--- Train DeepSurv Model ---\n",
      "✅ Required features validated.\n",
      "\n",
      "📊 Checking Data Before Training DeepSurv (Detailed NaN Check):\n",
      "Feature Shape: (1223009, 4), Durations Shape: (1223009,), Events Shape: (1223009,)\n",
      "NaN counts per column BEFORE training:\n",
      "stress_score       0\n",
      "avg_bmi            0\n",
      "smoking_prev       0\n",
      "global_life_exp    0\n",
      "T                  0\n",
      "censored           0\n",
      "dtype: int64\n",
      "Total NaNs in Features and Targets BEFORE training: 0\n",
      "Total NaNs in Features (X): 0\n",
      "NaNs in Durations: 0\n",
      "NaNs in Events: 0\n",
      "Sample Features:\n",
      "[[ 1.         65.4         0.6        81.89512   ]\n",
      " [ 0.5555556  25.          0.45016602 81.20488   ]\n",
      " [ 1.         65.4         0.6        81.89512   ]\n",
      " [ 0.5555556  25.          0.6        81.89512   ]\n",
      " [ 0.5555556  25.          0.6        81.89512   ]]\n",
      "Sample Durations: [67. 49. 56. 35. 57.]\n",
      "Sample Events: [1 1 1 1 1]\n",
      "Unique event values (should be 0 or 1): [0 1]\n",
      "\n",
      "✅ No NaNs detected in 'T' column (so far in NaN check).\n",
      "✅ No NaNs in input data for training.\n",
      "   ✅ Data split into training and validation sets.\n",
      "   ✅ Features normalized using StandardScaler.\n",
      "NaNs in Scaled X_train: 0\n",
      "NaNs in Scaled X_val: 0\n",
      "✅ No NaNs in scaled data.\n",
      "\n",
      "📊 Data Sanity Check RIGHT BEFORE model.fit():\n",
      "X_train NaNs: 0, Durations NaNs: 0, Events NaNs: 0\n",
      "X_val NaNs: 0, Durations Val NaNs: 0, Events Val NaNs: 0\n",
      "X_train dtype: float32, Durations dtype: float32, Events dtype: int64\n",
      "X_train min/max: -12.2270 / 2.4931\n",
      "Durations min/max: 0.0000 / 120.0000\n",
      "Events unique values: [0 1]\n",
      "\n",
      "🚀 Training DeepSurv Model...\n",
      "✅ DeepSurv Model Initialized with 4 input features.\n",
      "Hidden Layers: [64, 64], Dropout: 0.1, Learning Rate: 0.0005\n",
      "Training parameters: Epochs=100, Batch Size=256, Verbose=True\n",
      "0:\t[11s / 11s],\t\ttrain_loss: 4.5274,\tval_loss: 7.9652\n",
      "1:\t[10s / 21s],\t\ttrain_loss: 4.5217,\tval_loss: 7.9642\n",
      "2:\t[10s / 32s],\t\ttrain_loss: 4.5206,\tval_loss: 7.9639\n",
      "3:\t[10s / 42s],\t\ttrain_loss: 4.5200,\tval_loss: 7.9630\n",
      "4:\t[12s / 54s],\t\ttrain_loss: 4.5195,\tval_loss: 7.9631\n",
      "5:\t[9s / 1m:4s],\t\ttrain_loss: 4.5193,\tval_loss: 7.9629\n",
      "6:\t[9s / 1m:14s],\t\ttrain_loss: 4.5191,\tval_loss: 7.9630\n",
      "7:\t[10s / 1m:24s],\t\ttrain_loss: 4.5188,\tval_loss: 7.9621\n",
      "8:\t[9s / 1m:34s],\t\ttrain_loss: 4.5186,\tval_loss: 7.9620\n",
      "9:\t[10s / 1m:44s],\t\ttrain_loss: 4.5185,\tval_loss: 7.9619\n",
      "10:\t[10s / 1m:54s],\t\ttrain_loss: 4.5183,\tval_loss: 7.9619\n",
      "11:\t[10s / 2m:5s],\t\ttrain_loss: 4.5180,\tval_loss: 7.9615\n",
      "12:\t[10s / 2m:15s],\t\ttrain_loss: 4.5180,\tval_loss: 7.9619\n",
      "13:\t[10s / 2m:25s],\t\ttrain_loss: 4.5177,\tval_loss: 7.9612\n",
      "14:\t[10s / 2m:36s],\t\ttrain_loss: 4.5175,\tval_loss: 7.9610\n",
      "15:\t[10s / 2m:46s],\t\ttrain_loss: 4.5172,\tval_loss: 7.9610\n",
      "16:\t[10s / 2m:56s],\t\ttrain_loss: 4.5171,\tval_loss: 7.9608\n",
      "17:\t[10s / 3m:6s],\t\ttrain_loss: 4.5171,\tval_loss: 7.9607\n",
      "18:\t[10s / 3m:17s],\t\ttrain_loss: 4.5171,\tval_loss: 7.9618\n",
      "19:\t[10s / 3m:27s],\t\ttrain_loss: 4.5169,\tval_loss: 7.9612\n",
      "20:\t[10s / 3m:37s],\t\ttrain_loss: 4.5170,\tval_loss: 7.9609\n",
      "21:\t[9s / 3m:47s],\t\ttrain_loss: 4.5169,\tval_loss: 7.9610\n",
      "22:\t[10s / 3m:57s],\t\ttrain_loss: 4.5169,\tval_loss: 7.9604\n",
      "23:\t[10s / 4m:8s],\t\ttrain_loss: 4.5167,\tval_loss: 7.9605\n",
      "24:\t[10s / 4m:18s],\t\ttrain_loss: 4.5167,\tval_loss: 7.9605\n",
      "25:\t[10s / 4m:28s],\t\ttrain_loss: 4.5168,\tval_loss: 7.9608\n",
      "26:\t[10s / 4m:39s],\t\ttrain_loss: 4.5168,\tval_loss: 7.9607\n",
      "27:\t[10s / 4m:49s],\t\ttrain_loss: 4.5167,\tval_loss: 7.9606\n",
      "28:\t[10s / 4m:59s],\t\ttrain_loss: 4.5165,\tval_loss: 7.9607\n",
      "29:\t[10s / 5m:9s],\t\ttrain_loss: 4.5166,\tval_loss: 7.9605\n",
      "30:\t[10s / 5m:20s],\t\ttrain_loss: 4.5166,\tval_loss: 7.9601\n",
      "31:\t[10s / 5m:30s],\t\ttrain_loss: 4.5166,\tval_loss: 7.9602\n",
      "32:\t[10s / 5m:41s],\t\ttrain_loss: 4.5165,\tval_loss: 7.9603\n",
      "33:\t[10s / 5m:51s],\t\ttrain_loss: 4.5165,\tval_loss: 7.9605\n",
      "34:\t[10s / 6m:1s],\t\ttrain_loss: 4.5164,\tval_loss: 7.9603\n",
      "35:\t[9s / 6m:11s],\t\ttrain_loss: 4.5163,\tval_loss: 7.9605\n",
      "36:\t[10s / 6m:21s],\t\ttrain_loss: 4.5164,\tval_loss: 7.9603\n",
      "37:\t[10s / 6m:31s],\t\ttrain_loss: 4.5163,\tval_loss: 7.9603\n",
      "38:\t[10s / 6m:41s],\t\ttrain_loss: 4.5163,\tval_loss: 7.9603\n",
      "39:\t[10s / 6m:52s],\t\ttrain_loss: 4.5164,\tval_loss: 7.9605\n",
      "40:\t[10s / 7m:2s],\t\ttrain_loss: 4.5163,\tval_loss: 7.9605\n",
      "\n",
      "📈 Training Logs:\n",
      "    train_loss  val_loss\n",
      "36      4.5164    7.9603\n",
      "37      4.5163    7.9603\n",
      "38      4.5163    7.9603\n",
      "39      4.5164    7.9605\n",
      "40      4.5163    7.9605\n",
      "\n",
      "--- Epoch 1 ---\n",
      "  Epoch 1, model.log or model.log.values is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41:\t[9s / 9s],\t\ttrain_loss: 4.5166,\tval_loss: 7.9604\n",
      "42:\t[10s / 20s],\t\ttrain_loss: 4.5164,\tval_loss: 7.9606\n",
      "43:\t[10s / 30s],\t\ttrain_loss: 4.5165,\tval_loss: 7.9604\n",
      "44:\t[10s / 40s],\t\ttrain_loss: 4.5164,\tval_loss: 7.9606\n",
      "45:\t[10s / 51s],\t\ttrain_loss: 4.5164,\tval_loss: 7.9604\n",
      "46:\t[10s / 1m:1s],\t\ttrain_loss: 4.5165,\tval_loss: 7.9603\n",
      "47:\t[9s / 1m:11s],\t\ttrain_loss: 4.5163,\tval_loss: 7.9603\n",
      "48:\t[10s / 1m:21s],\t\ttrain_loss: 4.5163,\tval_loss: 7.9603\n",
      "49:\t[10s / 1m:31s],\t\ttrain_loss: 4.5163,\tval_loss: 7.9604\n",
      "50:\t[10s / 1m:41s],\t\ttrain_loss: 4.5162,\tval_loss: 7.9603\n",
      "51:\t[10s / 1m:51s],\t\ttrain_loss: 4.5163,\tval_loss: 7.9602\n",
      "52:\t[10s / 2m:1s],\t\ttrain_loss: 4.5163,\tval_loss: 7.9606\n",
      "53:\t[10s / 2m:11s],\t\ttrain_loss: 4.5164,\tval_loss: 7.9605\n",
      "54:\t[10s / 2m:22s],\t\ttrain_loss: 4.5162,\tval_loss: 7.9602\n",
      "55:\t[10s / 2m:32s],\t\ttrain_loss: 4.5163,\tval_loss: 7.9605\n",
      "56:\t[10s / 2m:43s],\t\ttrain_loss: 4.5162,\tval_loss: 7.9604\n",
      "57:\t[10s / 2m:53s],\t\ttrain_loss: 4.5163,\tval_loss: 7.9604\n",
      "58:\t[10s / 3m:3s],\t\ttrain_loss: 4.5162,\tval_loss: 7.9601\n",
      "59:\t[10s / 3m:13s],\t\ttrain_loss: 4.5162,\tval_loss: 7.9603\n",
      "60:\t[9s / 3m:23s],\t\ttrain_loss: 4.5160,\tval_loss: 7.9603\n",
      "61:\t[10s / 3m:33s],\t\ttrain_loss: 4.5161,\tval_loss: 7.9604\n",
      "62:\t[10s / 3m:43s],\t\ttrain_loss: 4.5161,\tval_loss: 7.9603\n",
      "63:\t[10s / 3m:53s],\t\ttrain_loss: 4.5161,\tval_loss: 7.9603\n",
      "64:\t[10s / 4m:3s],\t\ttrain_loss: 4.5161,\tval_loss: 7.9604\n",
      "65:\t[9s / 4m:13s],\t\ttrain_loss: 4.5161,\tval_loss: 7.9601\n",
      "66:\t[10s / 4m:23s],\t\ttrain_loss: 4.5162,\tval_loss: 7.9603\n",
      "67:\t[10s / 4m:33s],\t\ttrain_loss: 4.5160,\tval_loss: 7.9604\n",
      "68:\t[10s / 4m:44s],\t\ttrain_loss: 4.5161,\tval_loss: 7.9601\n",
      "\n",
      "📈 Training Logs:\n",
      "    train_loss  val_loss\n",
      "64      4.5161    7.9604\n",
      "65      4.5161    7.9601\n",
      "66      4.5162    7.9603\n",
      "67      4.5160    7.9604\n",
      "68      4.5161    7.9601\n",
      "\n",
      "--- Epoch 2 ---\n",
      "  Epoch 2, model.log or model.log.values is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69:\t[10s / 10s],\t\ttrain_loss: 4.5162,\tval_loss: 7.9602\n",
      "70:\t[10s / 20s],\t\ttrain_loss: 4.5162,\tval_loss: 7.9604\n",
      "71:\t[10s / 30s],\t\ttrain_loss: 4.5161,\tval_loss: 7.9603\n",
      "72:\t[10s / 41s],\t\ttrain_loss: 4.5161,\tval_loss: 7.9602\n",
      "73:\t[10s / 51s],\t\ttrain_loss: 4.5161,\tval_loss: 7.9605\n",
      "74:\t[10s / 1m:1s],\t\ttrain_loss: 4.5161,\tval_loss: 7.9607\n",
      "75:\t[10s / 1m:11s],\t\ttrain_loss: 4.5161,\tval_loss: 7.9602\n",
      "76:\t[9s / 1m:21s],\t\ttrain_loss: 4.5160,\tval_loss: 7.9602\n",
      "77:\t[9s / 1m:31s],\t\ttrain_loss: 4.5162,\tval_loss: 7.9601\n",
      "78:\t[10s / 1m:41s],\t\ttrain_loss: 4.5160,\tval_loss: 7.9603\n",
      "79:\t[9s / 1m:51s],\t\ttrain_loss: 4.5161,\tval_loss: 7.9604\n",
      "80:\t[9s / 2m:1s],\t\ttrain_loss: 4.5161,\tval_loss: 7.9602\n",
      "81:\t[9s / 2m:10s],\t\ttrain_loss: 4.5161,\tval_loss: 7.9603\n",
      "82:\t[9s / 2m:20s],\t\ttrain_loss: 4.5159,\tval_loss: 7.9602\n",
      "83:\t[9s / 2m:30s],\t\ttrain_loss: 4.5159,\tval_loss: 7.9602\n",
      "84:\t[9s / 2m:40s],\t\ttrain_loss: 4.5161,\tval_loss: 7.9601\n",
      "85:\t[10s / 2m:50s],\t\ttrain_loss: 4.5162,\tval_loss: 7.9605\n",
      "86:\t[9s / 3m:0s],\t\ttrain_loss: 4.5159,\tval_loss: 7.9602\n",
      "87:\t[9s / 3m:10s],\t\ttrain_loss: 4.5161,\tval_loss: 7.9603\n",
      "88:\t[9s / 3m:20s],\t\ttrain_loss: 4.5159,\tval_loss: 7.9606\n",
      "89:\t[9s / 3m:30s],\t\ttrain_loss: 4.5160,\tval_loss: 7.9603\n",
      "90:\t[10s / 3m:40s],\t\ttrain_loss: 4.5160,\tval_loss: 7.9603\n",
      "91:\t[9s / 3m:49s],\t\ttrain_loss: 4.5161,\tval_loss: 7.9600\n",
      "92:\t[9s / 3m:59s],\t\ttrain_loss: 4.5160,\tval_loss: 7.9600\n",
      "93:\t[9s / 4m:9s],\t\ttrain_loss: 4.5159,\tval_loss: 7.9601\n",
      "94:\t[9s / 4m:19s],\t\ttrain_loss: 4.5159,\tval_loss: 7.9601\n",
      "95:\t[9s / 4m:29s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9601\n",
      "96:\t[9s / 4m:39s],\t\ttrain_loss: 4.5159,\tval_loss: 7.9605\n",
      "97:\t[9s / 4m:48s],\t\ttrain_loss: 4.5160,\tval_loss: 7.9609\n",
      "98:\t[9s / 4m:58s],\t\ttrain_loss: 4.5160,\tval_loss: 7.9600\n",
      "99:\t[10s / 5m:8s],\t\ttrain_loss: 4.5159,\tval_loss: 7.9601\n",
      "100:\t[9s / 5m:18s],\t\ttrain_loss: 4.5160,\tval_loss: 7.9602\n",
      "101:\t[9s / 5m:28s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9601\n",
      "102:\t[10s / 5m:38s],\t\ttrain_loss: 4.5159,\tval_loss: 7.9605\n",
      "\n",
      "📈 Training Logs:\n",
      "     train_loss  val_loss\n",
      "98       4.5160    7.9600\n",
      "99       4.5159    7.9601\n",
      "100      4.5160    7.9602\n",
      "101      4.5158    7.9601\n",
      "102      4.5159    7.9605\n",
      "\n",
      "--- Epoch 3 ---\n",
      "  Epoch 3, model.log or model.log.values is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103:\t[10s / 10s],\t\ttrain_loss: 4.5159,\tval_loss: 7.9600\n",
      "104:\t[10s / 20s],\t\ttrain_loss: 4.5160,\tval_loss: 7.9601\n",
      "105:\t[10s / 30s],\t\ttrain_loss: 4.5159,\tval_loss: 7.9603\n",
      "106:\t[9s / 40s],\t\ttrain_loss: 4.5159,\tval_loss: 7.9601\n",
      "107:\t[10s / 50s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9601\n",
      "108:\t[10s / 1m:0s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9603\n",
      "109:\t[9s / 1m:10s],\t\ttrain_loss: 4.5159,\tval_loss: 7.9600\n",
      "110:\t[9s / 1m:20s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9607\n",
      "111:\t[9s / 1m:29s],\t\ttrain_loss: 4.5159,\tval_loss: 7.9601\n",
      "112:\t[9s / 1m:39s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9604\n",
      "113:\t[9s / 1m:49s],\t\ttrain_loss: 4.5159,\tval_loss: 7.9600\n",
      "114:\t[10s / 1m:59s],\t\ttrain_loss: 4.5160,\tval_loss: 7.9603\n",
      "115:\t[10s / 2m:10s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9602\n",
      "116:\t[10s / 2m:20s],\t\ttrain_loss: 4.5159,\tval_loss: 7.9600\n",
      "117:\t[9s / 2m:30s],\t\ttrain_loss: 4.5159,\tval_loss: 7.9606\n",
      "118:\t[10s / 2m:40s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9606\n",
      "119:\t[10s / 2m:50s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9600\n",
      "\n",
      "📈 Training Logs:\n",
      "     train_loss  val_loss\n",
      "115      4.5158    7.9602\n",
      "116      4.5159    7.9600\n",
      "117      4.5159    7.9606\n",
      "118      4.5158    7.9606\n",
      "119      4.5158    7.9600\n",
      "\n",
      "--- Epoch 4 ---\n",
      "  Epoch 4, model.log or model.log.values is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120:\t[10s / 10s],\t\ttrain_loss: 4.5159,\tval_loss: 7.9605\n",
      "121:\t[10s / 20s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9602\n",
      "122:\t[10s / 30s],\t\ttrain_loss: 4.5159,\tval_loss: 7.9600\n",
      "123:\t[9s / 40s],\t\ttrain_loss: 4.5159,\tval_loss: 7.9601\n",
      "124:\t[9s / 50s],\t\ttrain_loss: 4.5159,\tval_loss: 7.9603\n",
      "125:\t[9s / 1m:0s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9600\n",
      "126:\t[10s / 1m:10s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9598\n",
      "127:\t[9s / 1m:20s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9600\n",
      "128:\t[9s / 1m:30s],\t\ttrain_loss: 4.5159,\tval_loss: 7.9603\n",
      "129:\t[10s / 1m:40s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9604\n",
      "130:\t[9s / 1m:50s],\t\ttrain_loss: 4.5159,\tval_loss: 7.9601\n",
      "131:\t[9s / 2m:0s],\t\ttrain_loss: 4.5159,\tval_loss: 7.9605\n",
      "132:\t[10s / 2m:10s],\t\ttrain_loss: 4.5159,\tval_loss: 7.9600\n",
      "133:\t[9s / 2m:20s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9603\n",
      "134:\t[9s / 2m:30s],\t\ttrain_loss: 4.5159,\tval_loss: 7.9599\n",
      "135:\t[9s / 2m:40s],\t\ttrain_loss: 4.5159,\tval_loss: 7.9606\n",
      "136:\t[9s / 2m:49s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9600\n",
      "\n",
      "📈 Training Logs:\n",
      "     train_loss  val_loss\n",
      "132      4.5159    7.9600\n",
      "133      4.5158    7.9603\n",
      "134      4.5159    7.9599\n",
      "135      4.5159    7.9606\n",
      "136      4.5158    7.9600\n",
      "\n",
      "--- Epoch 5 ---\n",
      "  Epoch 5, model.log or model.log.values is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137:\t[9s / 9s],\t\ttrain_loss: 4.5159,\tval_loss: 7.9603\n",
      "138:\t[9s / 19s],\t\ttrain_loss: 4.5159,\tval_loss: 7.9602\n",
      "139:\t[9s / 29s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9603\n",
      "140:\t[9s / 39s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9598\n",
      "141:\t[10s / 49s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9601\n",
      "142:\t[9s / 59s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9600\n",
      "143:\t[10s / 1m:9s],\t\ttrain_loss: 4.5159,\tval_loss: 7.9601\n",
      "144:\t[10s / 1m:19s],\t\ttrain_loss: 4.5159,\tval_loss: 7.9603\n",
      "145:\t[10s / 1m:29s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9599\n",
      "146:\t[9s / 1m:39s],\t\ttrain_loss: 4.5157,\tval_loss: 7.9601\n",
      "147:\t[9s / 1m:49s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9600\n",
      "148:\t[9s / 1m:59s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9601\n",
      "149:\t[9s / 2m:9s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9603\n",
      "150:\t[10s / 2m:19s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9600\n",
      "\n",
      "📈 Training Logs:\n",
      "     train_loss  val_loss\n",
      "146      4.5157    7.9601\n",
      "147      4.5158    7.9600\n",
      "148      4.5158    7.9601\n",
      "149      4.5158    7.9603\n",
      "150      4.5158    7.9600\n",
      "\n",
      "--- Epoch 6 ---\n",
      "  Epoch 6, model.log or model.log.values is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151:\t[10s / 10s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9601\n",
      "152:\t[9s / 20s],\t\ttrain_loss: 4.5157,\tval_loss: 7.9602\n",
      "153:\t[9s / 29s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9602\n",
      "154:\t[9s / 39s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9602\n",
      "155:\t[9s / 49s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9600\n",
      "156:\t[9s / 59s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9602\n",
      "157:\t[9s / 1m:9s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9599\n",
      "158:\t[9s / 1m:19s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9606\n",
      "159:\t[9s / 1m:29s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9603\n",
      "160:\t[10s / 1m:39s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9601\n",
      "161:\t[10s / 1m:49s],\t\ttrain_loss: 4.5157,\tval_loss: 7.9603\n",
      "162:\t[10s / 1m:59s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9602\n",
      "163:\t[9s / 2m:9s],\t\ttrain_loss: 4.5157,\tval_loss: 7.9599\n",
      "164:\t[9s / 2m:19s],\t\ttrain_loss: 4.5157,\tval_loss: 7.9601\n",
      "165:\t[9s / 2m:29s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9608\n",
      "166:\t[9s / 2m:39s],\t\ttrain_loss: 4.5159,\tval_loss: 7.9600\n",
      "167:\t[9s / 2m:48s],\t\ttrain_loss: 4.5157,\tval_loss: 7.9604\n",
      "168:\t[9s / 2m:58s],\t\ttrain_loss: 4.5157,\tval_loss: 7.9600\n",
      "169:\t[9s / 3m:8s],\t\ttrain_loss: 4.5156,\tval_loss: 7.9601\n",
      "170:\t[9s / 3m:18s],\t\ttrain_loss: 4.5157,\tval_loss: 7.9604\n",
      "171:\t[9s / 3m:28s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9604\n",
      "172:\t[9s / 3m:38s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9601\n",
      "173:\t[9s / 3m:47s],\t\ttrain_loss: 4.5157,\tval_loss: 7.9600\n",
      "\n",
      "📈 Training Logs:\n",
      "     train_loss  val_loss\n",
      "169      4.5156    7.9601\n",
      "170      4.5157    7.9604\n",
      "171      4.5158    7.9604\n",
      "172      4.5158    7.9601\n",
      "173      4.5157    7.9600\n",
      "\n",
      "--- Epoch 7 ---\n",
      "  Epoch 7, model.log or model.log.values is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/torchtuples/base.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(path, **kwargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174:\t[10s / 10s],\t\ttrain_loss: 4.5157,\tval_loss: 7.9603\n",
      "175:\t[10s / 20s],\t\ttrain_loss: 4.5157,\tval_loss: 7.9610\n",
      "176:\t[10s / 30s],\t\ttrain_loss: 4.5157,\tval_loss: 7.9600\n",
      "177:\t[9s / 40s],\t\ttrain_loss: 4.5157,\tval_loss: 7.9600\n",
      "178:\t[9s / 50s],\t\ttrain_loss: 4.5158,\tval_loss: 7.9604\n",
      "179:\t[9s / 1m:0s],\t\ttrain_loss: 4.5156,\tval_loss: 7.9600\n",
      "180:\t[10s / 1m:10s],\t\ttrain_loss: 4.5156,\tval_loss: 7.9598\n",
      "181:\t[10s / 1m:20s],\t\ttrain_loss: 4.5157,\tval_loss: 7.9598\n",
      "182:\t[10s / 1m:30s],\t\ttrain_loss: 4.5157,\tval_loss: 7.9600\n",
      "183:\t[10s / 1m:41s],\t\ttrain_loss: 4.5155,\tval_loss: 7.9599\n",
      "184:\t[10s / 1m:51s],\t\ttrain_loss: 4.5156,\tval_loss: 7.9600\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   Sample age_df countries: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprocessed_batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCountry\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()[:\u001b[38;5;241m20\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# Print first 20 unique countries\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 2️⃣ Train DeepSurv\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m deepsurv_model, X_val, durations_val, events_val \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_deepsurv_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessed_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# 3️⃣ Evaluate Model\u001b[39;00m\n\u001b[1;32m      9\u001b[0m evaluate_deepsurv_model(deepsurv_model, X_val, durations_val, events_val)\n",
      "Cell \u001b[0;32mIn[74], line 104\u001b[0m, in \u001b[0;36mtrain_deepsurv_model\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# ✅ SIMPLIFIED EPOCH LOOP - Inspecting model.log Directly\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs): \u001b[38;5;66;03m# Manual epoch loop\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     log \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdurations_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevents_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdurations_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevents_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m📈 Training Logs:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28mprint\u001b[39m(log\u001b[38;5;241m.\u001b[39mto_pandas()\u001b[38;5;241m.\u001b[39mtail())\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pycox/models/cox.py:51\u001b[0m, in \u001b[0;36m_CoxBase.fit\u001b[0;34m(self, input, target, batch_size, epochs, callbacks, verbose, num_workers, shuffle, metrics, val_data, val_batch_size, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit  model with inputs and targets. Where 'input' is the covariates, and\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m'target' is a tuple with (durations, events).\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m    TrainingLogger -- Training log\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_data \u001b[38;5;241m=\u001b[39m tt\u001b[38;5;241m.\u001b[39mtuplefy(\u001b[38;5;28minput\u001b[39m, target)\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                   \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/torchtuples/base.py:294\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, input, target, batch_size, epochs, callbacks, verbose, num_workers, shuffle, metrics, val_data, val_batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (is_dl(val_data) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (val_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    291\u001b[0m     val_dataloader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_dataloader(\n\u001b[1;32m    292\u001b[0m         val_data, val_batch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39mnum_workers, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    293\u001b[0m     )\n\u001b[0;32m--> 294\u001b[0m log \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m log\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/torchtuples/base.py:236\u001b[0m, in \u001b[0;36mModel.fit_dataloader\u001b[0;34m(self, dataloader, epochs, callbacks, verbose, metrics, val_dataloader)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/torchtuples/base.py:180\u001b[0m, in \u001b[0;36mModel.compute_metrics\u001b[0;34m(self, data, metrics)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_device(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    179\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_device(target)\n\u001b[0;32m--> 180\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m out \u001b[38;5;241m=\u001b[39m tuplefy(out)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {name: metric(\u001b[38;5;241m*\u001b[39mout, \u001b[38;5;241m*\u001b[39mtarget) \u001b[38;5;28;01mfor\u001b[39;00m name, metric \u001b[38;5;129;01min\u001b[39;00m metrics\u001b[38;5;241m.\u001b[39mitems()}\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/torchtuples/practical.py:84\u001b[0m, in \u001b[0;36mMLPVanilla.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/torchtuples/practical.py:61\u001b[0m, in \u001b[0;36mDenseVanillaBlock.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m))\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_norm:\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout:\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28minput\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    186\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/functional.py:2812\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2809\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2810\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2812\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2813\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2815\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2816\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2817\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2818\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2819\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2820\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2821\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2822\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 1️⃣ Process the Dataset\n",
    "processed_batch = enhanced_feature_engineering(age_df, life_exp_df, global_le_df, death_rates_df)\n",
    "print(f\"   Sample age_df countries: {processed_batch['Country'].unique()[:20]}\") # Print first 20 unique countries\n",
    "\n",
    "# 2️⃣ Train DeepSurv\n",
    "deepsurv_model, X_val, durations_val, events_val = train_deepsurv_model(processed_batch)\n",
    "\n",
    "# 3️⃣ Evaluate Model\n",
    "evaluate_deepsurv_model(deepsurv_model, X_val, durations_val, events_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
