{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabnet Survival anaysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U sentence-transformers > /dev/null 2>&1\n",
    "!pip install xgboost > /dev/null 2>&1\n",
    "!pip install scikit-learn==1.4.2 scikit-survival==0.23.1 > /dev/null 2>&1\n",
    "!pip install torchtuples > /dev/null 2>&1\n",
    "!pip install pycox > /dev/null 2>&1\n",
    "!pip install numpy==1.21.5  > /dev/null 2>&1\n",
    "!pip install interpret-core  > /dev/null 2>&1\n",
    "!pip install lightgbm > /dev/null 2>&1\n",
    "!pip install shap > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import gc\n",
    "import kagglehub\n",
    "import contextlib\n",
    "import logging\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "import torch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.7).\n",
      "Life Expectancy Sample:\n",
      "       Country  Year      Status  Life expectancy   Adult Mortality  \\\n",
      "0  Afghanistan  2015  Developing              65.0            263.0   \n",
      "1  Afghanistan  2014  Developing              59.9            271.0   \n",
      "2  Afghanistan  2013  Developing              59.9            268.0   \n",
      "3  Afghanistan  2012  Developing              59.5            272.0   \n",
      "4  Afghanistan  2011  Developing              59.2            275.0   \n",
      "\n",
      "   infant deaths  Alcohol  percentage expenditure  Hepatitis B  Measles   ...  \\\n",
      "0             62     0.01               71.279624         65.0      1154  ...   \n",
      "1             64     0.01               73.523582         62.0       492  ...   \n",
      "2             66     0.01               73.219243         64.0       430  ...   \n",
      "3             69     0.01               78.184215         67.0      2787  ...   \n",
      "4             71     0.01                7.097109         68.0      3013  ...   \n",
      "\n",
      "   Polio  Total expenditure  Diphtheria    HIV/AIDS         GDP  Population  \\\n",
      "0    6.0               8.16         65.0        0.1  584.259210  33736494.0   \n",
      "1   58.0               8.18         62.0        0.1  612.696514    327582.0   \n",
      "2   62.0               8.13         64.0        0.1  631.744976  31731688.0   \n",
      "3   67.0               8.52         67.0        0.1  669.959000   3696958.0   \n",
      "4   68.0               7.87         68.0        0.1   63.537231   2978599.0   \n",
      "\n",
      "    thinness  1-19 years   thinness 5-9 years  \\\n",
      "0                   17.2                 17.3   \n",
      "1                   17.5                 17.5   \n",
      "2                   17.7                 17.7   \n",
      "3                   17.9                 18.0   \n",
      "4                   18.2                 18.2   \n",
      "\n",
      "   Income composition of resources  Schooling  \n",
      "0                            0.479       10.1  \n",
      "1                            0.476       10.0  \n",
      "2                            0.470        9.9  \n",
      "3                            0.463        9.8  \n",
      "4                            0.454        9.5  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.7).\n",
      "Heart Failure Sample:\n",
      "   Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  MaxHR  \\\n",
      "0   40   M           ATA        140          289          0     Normal    172   \n",
      "1   49   F           NAP        160          180          0     Normal    156   \n",
      "2   37   M           ATA        130          283          0         ST     98   \n",
      "3   48   F           ASY        138          214          0     Normal    108   \n",
      "4   54   M           NAP        150          195          0     Normal    122   \n",
      "\n",
      "  ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n",
      "0              N      0.0       Up             0  \n",
      "1              N      1.0     Flat             1  \n",
      "2              N      0.0       Up             0  \n",
      "3              Y      1.5     Flat             1  \n",
      "4              N      0.0       Up             0  \n",
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.7).\n",
      "Age Dataset Sample:\n",
      "     Id                     Name  \\\n",
      "0   Q23        George Washington   \n",
      "1   Q42            Douglas Adams   \n",
      "2   Q91          Abraham Lincoln   \n",
      "3  Q254  Wolfgang Amadeus Mozart   \n",
      "4  Q255     Ludwig van Beethoven   \n",
      "\n",
      "                                 Short description Gender  \\\n",
      "0   1st president of the United States (1732â€“1799)   Male   \n",
      "1                      English writer and humorist   Male   \n",
      "2  16th president of the United States (1809-1865)   Male   \n",
      "3        Austrian composer of the Classical period   Male   \n",
      "4           German classical and romantic composer   Male   \n",
      "\n",
      "                                             Country  Occupation  Birth year  \\\n",
      "0  United States of America; Kingdom of Great Bri...  Politician        1732   \n",
      "1                                     United Kingdom      Artist        1952   \n",
      "2                           United States of America  Politician        1809   \n",
      "3    Archduchy of Austria; Archbishopric of Salzburg      Artist        1756   \n",
      "4                 Holy Roman Empire; Austrian Empire      Artist        1770   \n",
      "\n",
      "   Death year Manner of death  Age of death  \n",
      "0      1799.0  natural causes          67.0  \n",
      "1      2001.0  natural causes          49.0  \n",
      "2      1865.0        homicide          56.0  \n",
      "3      1791.0             NaN          35.0  \n",
      "4      1827.0             NaN          57.0  \n",
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.7).\n",
      "World Important Events Sample:\n",
      "   Sl. No                      Name of Incident     Date    Month     Year  \\\n",
      "0       1  Indus Valley Civilization Flourishes  Unknown  Unknown  2600 BC   \n",
      "1       2               Battle of the Ten Kings  Unknown  Unknown  1400 BC   \n",
      "2       6  Establishment of the Delhi Sultanate  Unknown  Unknown     1206   \n",
      "3       7                     Battle of Panipat       21    April     1526   \n",
      "4       8          Establishment of British Raj        1      May     1858   \n",
      "\n",
      "  Country Type of Event    Place Name  \\\n",
      "0   India  Civilization  Indus Valley   \n",
      "1   India        Battle        Punjab   \n",
      "2   India     Political         Delhi   \n",
      "3   India        Battle       Panipat   \n",
      "4   India      Colonial   Whole India   \n",
      "\n",
      "                                              Impact  \\\n",
      "0  Development of one of the world's earliest urb...   \n",
      "1  Rigvedic tribes consolidated their control ove...   \n",
      "2          Muslim rule established in parts of India   \n",
      "3           Foundation of the Mughal Empire in India   \n",
      "4        Start of direct British governance in India   \n",
      "\n",
      "                       Affected Population Important Person/Group Responsible  \\\n",
      "0                        Local inhabitants                Indus Valley people   \n",
      "1                          Rigvedic tribes                              Sudas   \n",
      "2  People of Delhi and surrounding regions      QutbUnknownudUnknowndin Aibak   \n",
      "3                 Northern Indian kingdoms                              Babur   \n",
      "4                      Indian subcontinent  British East India Company/Empire   \n",
      "\n",
      "    Outcome  \n",
      "0  Positive  \n",
      "1  Positive  \n",
      "2     Mixed  \n",
      "3     Mixed  \n",
      "4  Negative  \n",
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.7).\n",
      "Historical Plane Crashes Sample:\n",
      "                 date     time                            location  \\\n",
      "0  September 17, 1908    17:18                 Fort Myer, Virginia   \n",
      "1  September 07, 1909        ?             Juvisy-sur-Orge, France   \n",
      "2       July 12, 1912    06:30           Atlantic City, New Jersey   \n",
      "3     August 06, 1913        ?  Victoria, British Columbia, Canada   \n",
      "4  September 09, 1913  c 18:30                  Over the North Sea   \n",
      "\n",
      "                 operator flight_no          route                 ac_type  \\\n",
      "0    Military - U.S. Army         ?  Demonstration        Wright Flyer III   \n",
      "1                       ?         ?       Air show          Wright Byplane   \n",
      "2    Military - U.S. Navy         ?    Test flight               Dirigible   \n",
      "3                 Private         ?              ?        Curtiss seaplane   \n",
      "4  Military - German Navy         ?              ?  Zeppelin L-1 (airship)   \n",
      "\n",
      "  registration cn_ln                       aboard  \\\n",
      "0            ?     1   2 Â  (passengers:1Â  crew:1)   \n",
      "1          SC1     ?   1 Â  (passengers:0Â  crew:1)   \n",
      "2            ?     ?   5 Â  (passengers:0Â  crew:5)   \n",
      "3            ?     ?   1 Â  (passengers:0Â  crew:1)   \n",
      "4            ?     ?  20 Â  (passengers:?Â  crew:?)   \n",
      "\n",
      "                    fatalities ground  \\\n",
      "0   1 Â  (passengers:1Â  crew:0)      0   \n",
      "1   1 Â  (passengers:0Â  crew:0)      0   \n",
      "2   5 Â  (passengers:0Â  crew:5)      0   \n",
      "3   1 Â  (passengers:0Â  crew:1)      0   \n",
      "4  14 Â  (passengers:?Â  crew:?)      0   \n",
      "\n",
      "                                             summary  \n",
      "0  During a demonstration flight, a U.S. Army fly...  \n",
      "1  Eugene Lefebvre was the first pilot to ever be...  \n",
      "2  First U.S. dirigible Akron exploded just offsh...  \n",
      "3  The first fatal airplane accident in Canada oc...  \n",
      "4  The airship flew into a thunderstorm and encou...  \n",
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.7).\n",
      "Global Life Expectancy Historical Dataset Sample:\n",
      "           Country Name Country Code    1960    1961    1962    1963    1964  \\\n",
      "0                 Aruba          ABW  65.662  66.074  66.444  66.787  67.113   \n",
      "1           Afghanistan          AFG  32.446  32.962  33.471  33.971  34.463   \n",
      "2                Angola          AGO  37.524  37.811  38.113  38.430  38.760   \n",
      "3               Albania          ALB  62.283  63.301  64.190  64.914  65.463   \n",
      "4  United Arab Emirates          ARE  51.537  52.560  53.573  54.572  55.555   \n",
      "\n",
      "     1965    1966    1967  ...    2011    2012    2013    2014    2015  \\\n",
      "0  67.435  67.762  68.095  ...  75.158  75.299  75.441  75.583  75.725   \n",
      "1  34.948  35.430  35.914  ...  61.553  62.054  62.525  62.966  63.377   \n",
      "2  39.102  39.454  39.813  ...  56.330  57.236  58.054  58.776  59.398   \n",
      "3  65.850  66.110  66.304  ...  76.914  77.252  77.554  77.813  78.025   \n",
      "4  56.523  57.482  58.432  ...  76.521  76.711  76.903  77.095  77.285   \n",
      "\n",
      "     2016    2017    2018    2019    2020  \n",
      "0  75.868  76.010  76.152  76.293  76.434  \n",
      "1  63.763  64.130  64.486  64.833  65.173  \n",
      "2  59.925  60.379  60.782  61.147  61.487  \n",
      "3  78.194  78.333  78.458  78.573  78.686  \n",
      "4  77.470  77.647  77.814  77.972  78.120  \n",
      "\n",
      "[5 rows x 63 columns]\n",
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.7).\n",
      "Death Rates United States Dataset Sample:\n",
      "                 INDICATOR                                               UNIT  \\\n",
      "0  Death rates for suicide  Deaths per 100,000 resident population, age-ad...   \n",
      "1  Death rates for suicide  Deaths per 100,000 resident population, age-ad...   \n",
      "2  Death rates for suicide  Deaths per 100,000 resident population, age-ad...   \n",
      "3  Death rates for suicide  Deaths per 100,000 resident population, age-ad...   \n",
      "4  Death rates for suicide  Deaths per 100,000 resident population, age-ad...   \n",
      "\n",
      "   UNIT_NUM STUB_NAME  STUB_NAME_NUM   STUB_LABEL  STUB_LABEL_NUM  YEAR  \\\n",
      "0         1     Total              0  All persons             0.0  1950   \n",
      "1         1     Total              0  All persons             0.0  1960   \n",
      "2         1     Total              0  All persons             0.0  1970   \n",
      "3         1     Total              0  All persons             0.0  1980   \n",
      "4         1     Total              0  All persons             0.0  1981   \n",
      "\n",
      "   YEAR_NUM       AGE  AGE_NUM  ESTIMATE  \n",
      "0         1  All ages      0.0      13.2  \n",
      "1         2  All ages      0.0      12.5  \n",
      "2         3  All ages      0.0      13.1  \n",
      "3         4  All ages      0.0      12.2  \n",
      "4         5  All ages      0.0      12.3  \n"
     ]
    }
   ],
   "source": [
    "# Life Expectancy dataset\n",
    "life_exp_path = kagglehub.dataset_download(\"kumarajarshi/life-expectancy-who\")\n",
    "life_exp_file = os.path.join(life_exp_path, \"Life Expectancy Data.csv\")\n",
    "life_exp_df = pd.read_csv(life_exp_file)\n",
    "print(\"Life Expectancy Sample:\")\n",
    "print(life_exp_df.head())\n",
    "\n",
    "# Heart Failure dataset (not used in LightGBM, but kept for context)\n",
    "heart_path = kagglehub.dataset_download(\"fedesoriano/heart-failure-prediction\")\n",
    "heart_file = os.path.join(heart_path, \"heart.csv\")\n",
    "heart_df = pd.read_csv(heart_file)\n",
    "print(\"Heart Failure Sample:\")\n",
    "print(heart_df.head())\n",
    "\n",
    "# Age Dataset\n",
    "age_path = kagglehub.dataset_download(\"imoore/age-dataset\")\n",
    "age_file = os.path.join(age_path, \"AgeDataset-V1.csv\")\n",
    "age_df = pd.read_csv(age_file)\n",
    "print(\"Age Dataset Sample:\")\n",
    "print(age_df.head())\n",
    "\n",
    "# World important events Dataset\n",
    "events_path = kagglehub.dataset_download(\"saketk511/world-important-events-ancient-to-modern\")\n",
    "events_file = os.path.join(events_path, \"World Important Dates.csv\")\n",
    "events_df = pd.read_csv(events_file)\n",
    "print(\"World Important Events Sample:\")\n",
    "print(events_df.head())\n",
    "\n",
    "# Plane Crash Dataset\n",
    "plane_crash_path = kagglehub.dataset_download(\"nguyenhoc/plane-crash\")\n",
    "plane_crash_file = os.path.join(plane_crash_path, \"planecrashinfo_20181121001952.csv\")  \n",
    "planes_df = pd.read_csv(plane_crash_file)\n",
    "print(\"Historical Plane Crashes Sample:\")\n",
    "print(planes_df.head())\n",
    "\n",
    "# Gloabl Life Expectancy dataset\n",
    "global_le_path = kagglehub.dataset_download(\"hasibalmuzdadid/global-life-expectancy-historical-dataset\")\n",
    "global_le_file = os.path.join(global_le_path, \"global life expectancy dataset.csv\")\n",
    "global_le_df = pd.read_csv(global_le_file)\n",
    "print(\"Global Life Expectancy Historical Dataset Sample:\")\n",
    "print(global_le_df.head())\n",
    "\n",
    "# US death rate Dataset\n",
    "death_rates_path = kagglehub.dataset_download(\"melissamonfared/death-rates-united-states\")\n",
    "death_rates_file = os.path.join(death_rates_path, \"Death_rates.csv\")\n",
    "death_rates_df = pd.read_csv(death_rates_file)\n",
    "print(\"Death Rates United States Dataset Sample:\")\n",
    "print(death_rates_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhanced_feature_engineering(df, life_exp_df, global_le_df, death_rates_df):\n",
    "    \"\"\"\n",
    "    Feature engineering for survival analysis using TabNet:\n",
    "    - Handles categorical encoding\n",
    "    - Creates meaningful health-related features\n",
    "    - Adds censoring and survival time variables\n",
    "    \"\"\"\n",
    "    # -------- Basic Cleaning --------\n",
    "    df['Country'] = df['Country'].str.split(';').str[0].str.strip()\n",
    "    df['Gender'] = np.where(df['Gender'] == 'Male', 1, np.where(df['Gender'] == 'Female', 0, 0.5))\n",
    "\n",
    "    # -------- Essential Features --------\n",
    "    stress_map = {'Politician': 9, 'Military personnel': 8, 'Journalist': 7,\n",
    "                  'Businessperson': 6, 'Artist': 5, 'Teacher': 4, \n",
    "                  'Researcher': 3, 'Other': 5, 'Unknown': 5}\n",
    "    df['stress_score'] = df['Occupation'].map(stress_map).fillna(5).astype('float32') / 9.0\n",
    "\n",
    "    # Get BMI from country statistics\n",
    "    life_exp_df[' BMI '] = pd.to_numeric(life_exp_df[' BMI '], errors='coerce')\n",
    "    country_bmi = life_exp_df.groupby('Country')[' BMI '].median().to_dict()\n",
    "    df['avg_bmi'] = df['Country'].map(country_bmi).fillna(25).astype('float32')\n",
    "\n",
    "    # Heart disease risk\n",
    "    df['heart_disease_risk'] = (0.4 * df['Gender'] +\n",
    "                                0.3 * df['stress_score'] +\n",
    "                                0.3 * df['avg_bmi']).astype('float32')\n",
    "\n",
    "    # Smoking Prevalence\n",
    "    df['smoking_prev'] = (1 / (1 + np.exp((df['Birth year'] - 1950) / 10))).astype('float32')\n",
    "    df['smoking_prev'] = np.clip(df['smoking_prev'], 0.1, 0.6)\n",
    "\n",
    "    # -------- Merge Country-Level Health Data --------\n",
    "    life_exp_filtered = life_exp_df.groupby('Country')[['Alcohol', 'GDP', 'Schooling']].median()\n",
    "    df = df.join(life_exp_filtered.add_prefix('country_'), on='Country', how='left')\n",
    "\n",
    "    # -------------------- FIX: Handle Global Life Expectancy Data --------------------\n",
    "    print(\"Global Life Expectancy Columns:\", global_le_df.columns)  # Debugging\n",
    "\n",
    "    # Rename for consistency\n",
    "    global_le_df = global_le_df.rename(columns={'Country Name': 'Country'})\n",
    "\n",
    "    # Convert from wide to long format (yearly data to single column)\n",
    "    global_le_df = global_le_df.melt(\n",
    "        id_vars=['Country'], \n",
    "        var_name='Year', \n",
    "        value_name='Life_Expectancy'\n",
    "    )\n",
    "\n",
    "    # Ensure numeric conversion and remove invalid values\n",
    "    global_le_df[\"Year\"] = pd.to_numeric(global_le_df[\"Year\"], errors='coerce')\n",
    "    global_le_df[\"Life_Expectancy\"] = pd.to_numeric(global_le_df[\"Life_Expectancy\"], errors='coerce')\n",
    "    global_le_df = global_le_df.dropna(subset=['Life_Expectancy'])\n",
    "\n",
    "    # Compute average life expectancy per country\n",
    "    global_le_agg = (\n",
    "        global_le_df.groupby(\"Country\")[\"Life_Expectancy\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    df = df.merge(global_le_agg.rename(columns={'Life_Expectancy': 'global_life_exp'}), on='Country', how='left')\n",
    "\n",
    "    # -------------------- FIX: Handle Death Rates Data --------------------\n",
    "    print(\"Death Rates Dataset Columns:\", death_rates_df.columns)  # Debugging\n",
    "\n",
    "    # Use the \"ESTIMATE\" column as Death Rate\n",
    "    correct_col = \"ESTIMATE\"\n",
    "\n",
    "    # Ensure numeric conversion\n",
    "    death_rates_df[correct_col] = pd.to_numeric(death_rates_df[correct_col], errors=\"coerce\")\n",
    "\n",
    "    # Group by Country and take the average death rate\n",
    "    death_rates_agg = death_rates_df.groupby(\"Country\")[correct_col].mean().reset_index()\n",
    "    death_rates_agg.rename(columns={correct_col: \"avg_death_rate\"}, inplace=True)\n",
    "\n",
    "    # Merge death rates with main dataset\n",
    "    df = df.merge(death_rates_agg, on=\"Country\", how=\"left\")\n",
    "\n",
    "\n",
    "    # -------------------- Compute Censoring & Survival Time --------------------\n",
    "    df['censored'] = (df['Death year'] > 2024).astype(int)  # 1 = alive (censored), 0 = dead\n",
    "    df['T'] = np.where(df['censored'] == 1, 2024 - df['Birth year'], df['Age of death'])\n",
    "    df['T'] = df['T'].clip(lower=0)  # Ensure no negative survival times\n",
    "\n",
    "    # -------------------- Remove Unnecessary Features --------------------\n",
    "    drop_cols = ['plane_crash_count', 'num_events', 'avg_plane_fatalities']\n",
    "    df = df.drop(columns=[col for col in drop_cols if col in df.columns])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tabnet(df):\n",
    "    \"\"\"\n",
    "    Trains a TabNet model for survival analysis using T (time-to-event) as the target.\n",
    "    \"\"\"\n",
    "    # Define features and target\n",
    "    features = ['stress_score', 'avg_bmi', 'heart_disease_risk', 'smoking_prev', \n",
    "                'country_Alcohol', 'global_life_exp']\n",
    "    \n",
    "    X = df[features]\n",
    "    y = df[['T', 'censored']]  # We need both time and event status for survival analysis\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Handle missing values with imputation\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    X_train = imputer.fit_transform(X_train)\n",
    "    X_val = imputer.transform(X_val)\n",
    "\n",
    "    # Convert target variables to PyTorch tensors\n",
    "    T_train = torch.tensor(y_train['T'].values, dtype=torch.float32).reshape(-1, 1)\n",
    "    C_train = torch.tensor(y_train['censored'].values, dtype=torch.float32).reshape(-1, 1)\n",
    "    T_val = torch.tensor(y_val['T'].values, dtype=torch.float32).reshape(-1, 1)\n",
    "    C_val = torch.tensor(y_val['censored'].values, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "    # TabNet Model\n",
    "    tabnet = TabNetRegressor()\n",
    "    \n",
    "    # Loss function: Negative Log Likelihood for survival analysis\n",
    "    def survival_loss(preds, T, C):\n",
    "        \"\"\"\n",
    "        Implements a loss function that considers censoring using Negative Log Likelihood.\n",
    "        \"\"\"\n",
    "        risk = -torch.log(preds) * (1 - C)  # Event observed\n",
    "        risk += -torch.log(1 - preds) * C   # Censored\n",
    "        return risk.mean()\n",
    "\n",
    "    # Training Loop\n",
    "    max_epochs = 100\n",
    "    batch_size = 512\n",
    "    for epoch in range(max_epochs):\n",
    "        tabnet.fit(\n",
    "            X_train, T_train,\n",
    "            eval_set=[(X_val, T_val)],\n",
    "            patience=10,\n",
    "            batch_size=batch_size,\n",
    "            virtual_batch_size=256\n",
    "        )\n",
    "        preds = tabnet.predict(X_val)\n",
    "        loss = survival_loss(torch.tensor(preds, dtype=torch.float32), T_val, C_val)\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "\n",
    "    return tabnet, X_val, y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- STEP 3: Evaluate Model with Concordance Index --------------------\n",
    "def evaluate_tabnet(tabnet, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Evaluates the survival model using Concordance Index (C-index).\n",
    "    \"\"\"\n",
    "    preds = tabnet.predict(X_val)  # Survival predictions\n",
    "    c_index = concordance_index(y_val['T'], -preds, y_val['censored'])\n",
    "    print(f\"Concordance Index: {c_index:.3f}\")\n",
    "    return c_index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Life Expectancy Columns: Index(['Country Name', 'Country Code', '1960', '1961', '1962', '1963', '1964',\n",
      "       '1965', '1966', '1967', '1968', '1969', '1970', '1971', '1972', '1973',\n",
      "       '1974', '1975', '1976', '1977', '1978', '1979', '1980', '1981', '1982',\n",
      "       '1983', '1984', '1985', '1986', '1987', '1988', '1989', '1990', '1991',\n",
      "       '1992', '1993', '1994', '1995', '1996', '1997', '1998', '1999', '2000',\n",
      "       '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009',\n",
      "       '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018',\n",
      "       '2019', '2020'],\n",
      "      dtype='object')\n",
      "Death Rates Dataset Columns: Index(['INDICATOR', 'UNIT', 'UNIT_NUM', 'STUB_NAME', 'STUB_NAME_NUM',\n",
      "       'STUB_LABEL', 'STUB_LABEL_NUM', 'YEAR', 'YEAR_NUM', 'AGE', 'AGE_NUM',\n",
      "       'ESTIMATE', 'Country'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "index -1 is out of bounds for dimension 1 with size 6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# -------------------- Execute Training & Evaluation --------------------\u001b[39;00m\n\u001b[1;32m      2\u001b[0m processed_batch \u001b[38;5;241m=\u001b[39m enhanced_feature_engineering(age_df, life_exp_df, global_le_df, death_rates_df)\n\u001b[0;32m----> 3\u001b[0m tabnet_model, X_val, y_val \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_tabnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessed_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m evaluate_tabnet(tabnet_model, X_val, y_val)\n",
      "Cell \u001b[0;32mIn[16], line 42\u001b[0m, in \u001b[0;36mtrain_tabnet\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     40\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_epochs):\n\u001b[0;32m---> 42\u001b[0m     \u001b[43mtabnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvirtual_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     preds \u001b[38;5;241m=\u001b[39m tabnet\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[1;32m     50\u001b[0m     loss \u001b[38;5;241m=\u001b[39m survival_loss(torch\u001b[38;5;241m.\u001b[39mtensor(preds, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32), T_val, C_val)\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pytorch_tabnet/abstract_model.py:258\u001b[0m, in \u001b[0;36mTabModel.fit\u001b[0;34m(self, X_train, y_train, eval_set, eval_name, eval_metric, loss_fn, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory, from_unsupervised, warm_start, augmentations, compute_importance)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_epochs):\n\u001b[1;32m    254\u001b[0m \n\u001b[1;32m    255\u001b[0m     \u001b[38;5;66;03m# Call method on_epoch_begin for all callbacks\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_container\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch_idx)\n\u001b[0;32m--> 258\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# Apply predict epoch to all eval sets\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m eval_name, valid_dataloader \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(eval_names, valid_dataloaders):\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pytorch_tabnet/abstract_model.py:489\u001b[0m, in \u001b[0;36mTabModel._train_epoch\u001b[0;34m(self, train_loader)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_container\u001b[38;5;241m.\u001b[39mon_batch_begin(batch_idx)\n\u001b[0;32m--> 489\u001b[0m     batch_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_container\u001b[38;5;241m.\u001b[39mon_batch_end(batch_idx, batch_logs)\n\u001b[1;32m    493\u001b[0m epoch_logs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pytorch_tabnet/abstract_model.py:527\u001b[0m, in \u001b[0;36mTabModel._train_batch\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[1;32m    525\u001b[0m     param\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 527\u001b[0m output, M_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    529\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(output, y)\n\u001b[1;32m    530\u001b[0m \u001b[38;5;66;03m# Add the overall sparsity loss\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pytorch_tabnet/tab_network.py:616\u001b[0m, in \u001b[0;36mTabNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    615\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedder(x)\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtabnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pytorch_tabnet/tab_network.py:492\u001b[0m, in \u001b[0;36mTabNetNoEmbeddings.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    491\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 492\u001b[0m     steps_output, M_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m     res \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(torch\u001b[38;5;241m.\u001b[39mstack(steps_output, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_multi_task:\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;66;03m# Result will be in list format\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pytorch_tabnet/tab_network.py:172\u001b[0m, in \u001b[0;36mTabNetEncoder.forward\u001b[0;34m(self, x, prior)\u001b[0m\n\u001b[1;32m    170\u001b[0m steps_output \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_steps):\n\u001b[0;32m--> 172\u001b[0m     M \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matt_transformers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m     M_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(\n\u001b[1;32m    174\u001b[0m         torch\u001b[38;5;241m.\u001b[39msum(torch\u001b[38;5;241m.\u001b[39mmul(M, torch\u001b[38;5;241m.\u001b[39mlog(M \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon)), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    175\u001b[0m     )\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;66;03m# update prior\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pytorch_tabnet/tab_network.py:671\u001b[0m, in \u001b[0;36mAttentiveTransformer.forward\u001b[0;34m(self, priors, processed_feat)\u001b[0m\n\u001b[1;32m    669\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn(x)\n\u001b[1;32m    670\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmul(x, priors)\n\u001b[0;32m--> 671\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pytorch_tabnet/sparsemax.py:109\u001b[0m, in \u001b[0;36mSparsemax.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msparsemax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/autograd/function.py:575\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    574\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    583\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pytorch_tabnet/sparsemax.py:52\u001b[0m, in \u001b[0;36mSparsemaxFunction.forward\u001b[0;34m(ctx, input, dim)\u001b[0m\n\u001b[1;32m     50\u001b[0m max_val, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mmax(dim\u001b[38;5;241m=\u001b[39mdim, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m max_val  \u001b[38;5;66;03m# same numerical stability trick as for softmax\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m tau, supp_size \u001b[38;5;241m=\u001b[39m \u001b[43mSparsemaxFunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_threshold_and_support\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;28minput\u001b[39m \u001b[38;5;241m-\u001b[39m tau, \u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     54\u001b[0m ctx\u001b[38;5;241m.\u001b[39msave_for_backward(supp_size, output)\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pytorch_tabnet/sparsemax.py:94\u001b[0m, in \u001b[0;36mSparsemaxFunction._threshold_and_support\u001b[0;34m(input, dim)\u001b[0m\n\u001b[1;32m     91\u001b[0m support \u001b[38;5;241m=\u001b[39m rhos \u001b[38;5;241m*\u001b[39m input_srt \u001b[38;5;241m>\u001b[39m input_cumsum\n\u001b[1;32m     93\u001b[0m support_size \u001b[38;5;241m=\u001b[39m support\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39mdim)\u001b[38;5;241m.\u001b[39munsqueeze(dim)\n\u001b[0;32m---> 94\u001b[0m tau \u001b[38;5;241m=\u001b[39m \u001b[43minput_cumsum\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msupport_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m tau \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m support_size\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tau, support_size\n",
      "\u001b[0;31mRuntimeError\u001b[0m: index -1 is out of bounds for dimension 1 with size 6"
     ]
    }
   ],
   "source": [
    "# -------------------- Execute Training & Evaluation --------------------\n",
    "processed_batch = enhanced_feature_engineering(age_df, life_exp_df, global_le_df, death_rates_df)\n",
    "tabnet_model, X_val, y_val = train_tabnet(processed_batch)\n",
    "evaluate_tabnet(tabnet_model, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
